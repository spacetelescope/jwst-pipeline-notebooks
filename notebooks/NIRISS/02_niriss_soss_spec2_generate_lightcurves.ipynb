{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/STScI-MIRI/MRS-ExampleNB/raw/main/assets/banner1.png' alt=\"stsci_logo\" width=\"1000px\"/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # TSO JWebbinar Notebook 1: Downloading and Calibrating `uncal` TSO Products -->\n",
    "# NIRISS/SOSS Notebook 2: Spectral Extracting and Lightcure Generation for TSO Products\n",
    "-----\n",
    "\n",
    "**Authors**:\n",
    "- **Tyler Baines** | Science Support Analyst | NIRISS Branch | tbaines@stsci.edu\n",
    "- **NÃ©stor Espinoza** | AURA Assistant Astronomer | Mission Scientist for Exoplanet Science | nespinoza@stsci.edu\n",
    "\n",
    "**Date Published**: May 1st, 2024\n",
    "\n",
    "**Last Updated**: May 1st, 2024 \n",
    "\n",
    "<!-- **Pipeline Version**: 1.12.5 -->\n",
    "\n",
    "## Table of contents\n",
    "1. [Introduction](#intro)<br>\n",
    "   1.1 [Purpose of this Notebook](#purpose)<br>\n",
    "   1.2 [Input Data](#inputs)<br>\n",
    "2. [Imports](#imports)<br>\n",
    "3. [A look at the input data - the `rateints` files](#quick-look)<br>\n",
    "4. [The JWST Stage 2 Pipeline `Spec2` and our custom steps](#custom)<br>\n",
    "   4.1 [ Identify and replace bad pixels](#bad)<br>\n",
    "   4.2 [Background Subtraction](#background_subtraction)<br>\n",
    "   4.3 [Spectral tracing](#tracing)<br>\n",
    "   4.4 [Remove 1/f noise from the 2dcutouts](#1overf)<br>\n",
    "   4.5 [Extract the spectra and obtain wavelength solution](#extraction)<br>\n",
    "   4.6 [Produce white and spectroscopic light curves](#lightcurve)<br>\n",
    "5. [Concluding remarks](#remarks)<br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.<font color='white'> </font>Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "### 1.1.<font color='white'>-</font>Purpose of this Notebook<a class=\"anchor\" id=\"purpose\"></a> ###\n",
    "\n",
    "In this notebook, we provide a practical guide for the exploration and generation of NIRISS SOSS light curves and is a continuation of the `01_niriss_soss_detector1_reduction` notebook. We will specifically focus on generating equivalent outputs to the `Spec2` stage of the JWST pipeline, adapting our approach to cater to the unique characteristics of NIRISS/SOSS data. Our process includes methods for spectral tracing and extraction for SOSS observations. The primary objective of this notebook is to fascillitate the production of both white and spectroscopic light curves (as well as fitting products), tailored to the JWST NIRISS/SOSS users for their specific data sets.\n",
    "\n",
    "### 1.2<font color='white'>-</font>Input Data<a class=\"anchor\" id=\"inputs\"></a> ###\n",
    "\n",
    "The input data for this notebook, a transit of WASP-39b observed with SOSS CLEAR/GR700XD, are the `Detector1 - RATEINTS` equivalent files produced following the `01_niriss_soss_detector1_reduction` notebook. The full WASP-39b dataset can be downloaded directly from MAST, however, we recommend using the products derived from the first notebook reproducbility purposes. The data set belongs to the <a href=\"https://www.stsci.edu/jwst/science-execution/approved-programs/dd-ers/program-1366\"> JWST Early Release Science program ERS-1366,</a> which includes 9 groups per integration and 538 integrations per exposure using the `SUBSTRIP256` subarray, covering a total of about 8.25 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports <a class=\"anchor\" id=\"imports\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "For this demonstration we will need the following packages to be installed in your python environemnt:\n",
    "1. numpy \n",
    "2. scipy\n",
    "3. astropy\n",
    "4. matplotlib\n",
    "5. jwst\n",
    "6. pastasoss (see section [4.3](#tracing) for more details about this package)\n",
    "\n",
    "If you completed the first notebook, you should have a working environment already setup up. If not, you can setup and working environment following these steps. \n",
    "\n",
    "```markdown\n",
    "conda create -n jwst-soss-demo-py3.10 python=3.10 pip\n",
    "conda activate jwst-soss-demo-py3.10\n",
    "pip install -r requirements-soss.txt\n",
    "```\n",
    "\n",
    "Next we'll import the various python packages that we're actually going to use in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ General Imports ------\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.convolution import interpolate_replace_nans\n",
    "\n",
    "\n",
    "# ------ JWST Calibration Pipeline Imports ------\n",
    "import jwst\n",
    "from jwst import datamodels\n",
    "\n",
    "# ------ PASTASOSS import ------\n",
    "import pastasoss\n",
    "\n",
    "# ------ Plotting Imports ------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# watermark allows one to see which package versions are being used and \n",
    "# some system specs which can be shared easily if problems arise. \n",
    "try: \n",
    "    %load_ext watermark\n",
    "    %watermark -v -m -p numpy,astropy,scipy,matplotlib,astroquery,jwst,pastasoss\n",
    "except:\n",
    "    print('versions')\n",
    "    print(f'{np.__name__:<10} : {np.__version__}')\n",
    "    print(f'{jwst.__name__:<10} : {jwst.__version__}')\n",
    "    print(f'{pastasoss.__name__:<10} : {pastasoss.__version__}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure plotting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,4)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "plt.rcParams['image.cmap'] = 'inferno'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A look at the input data - the `rateints` files <a class=\"anchor\" id=\"quick-look\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "Let's load in the calibrated data product results from the `01_niriss_soss_detector1_reduction` notebook and do a quick inspection again. Then we'll proceed to perform an additional number of steps that would take place during the `Spec2` step such as background subtract and correcting 1/f noise. The `rateints` files contain the slope images for each integration, which is the product we want to use for our analysis. Let's take a look at the contents of the first segment file using the JWST datamodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateints_data_folder = \"data/calibrated/\"\n",
    "\n",
    "files = [\n",
    "    \"jw01366001001_04101_00001-seg001_nis_1_rampfitstep.fits\", \n",
    "    \"jw01366001001_04101_00001-seg002_nis_1_rampfitstep.fits\", \n",
    "    \"jw01366001001_04101_00001-seg003_nis_1_rampfitstep.fits\", \n",
    "    \"jw01366001001_04101_00001-seg004_nis_1_rampfitstep.fits\", \n",
    "]\n",
    "\n",
    "rateints = datamodels.open(rateints_data_folder+files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateints.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = 0\n",
    "vmax = 20\n",
    "\n",
    "sl_fig, axs = plt.subplots(ncols=1, nrows=5, figsize=[18, 17], sharex=True)\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    im = ax.imshow(rateints.data[i, :, :], vmin=vmin, vmax=vmax)\n",
    "    if i == 2:\n",
    "        ax.set_ylabel('Y-row, pixel', fontsize=15)\n",
    "    ax.set_title('int = {0}'.format(i+1))\n",
    "\n",
    "ax.set_xlabel('X-column, pixel', fontsize=15)\n",
    "sl_fig.subplots_adjust(right=0.95)\n",
    "cbar_ax = sl_fig.add_axes([0.98, 0.2, 0.02, 0.6])\n",
    "cbar = sl_fig.colorbar(im, cax=cbar_ax)\n",
    "cbar.set_label('DN/s', fontsize='x-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The JWST Stage 2 Pipeline `Spec2` and our custom steps <a class=\"anchor\" id=\"custom\"></a>\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "### 4.1 Identify and replace bad pixels <a class=\"anchor\" id=\"bad\"></a>\n",
    "\n",
    "Looking at these images we can see that each contains a number of bad pixels. We could in theory leave these pixels and continue our analysis. However, when it comes to centroiding and tracing spectra or spectral extraction, it is better to assign some values to these bad pixels. In this step, we will replace these bad pixel. There are many ways to go about doing this step in addition to a step in the pipeline for bad pixel replace. Here we're going to make use of `astropy`'s bad pixel replacement using the `interpolate_replace_nans` method. This this step may take some time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_bad_pixels = True\n",
    "\n",
    "with_bad_pixels = np.copy(rateints.data[0])\n",
    "\n",
    "if replace_bad_pixels:\n",
    "    kernel = Gaussian2DKernel(3, 3)\n",
    "    for i, image in enumerate(rateints.data):\n",
    "        rateints.data[i] = interpolate_replace_nans(image, kernel)\n",
    "else:\n",
    "    rateints.data = np.nan_to_num(rateints.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, constrained_layout=True)\n",
    "\n",
    "ax1, ax2 = axes\n",
    "\n",
    "ax1.set_title('Int = 1')\n",
    "ax1.set_xlabel('x [pixel]')\n",
    "ax1.set_ylabel('y [pixel]')\n",
    "ax1.imshow(with_bad_pixels, vmin=0, vmax=20)\n",
    "fig.colorbar(ax=ax1, label='DN/s')\n",
    "\n",
    "ax2.set_title('Int = 1, w/ Bad Pixel Replacement')\n",
    "ax2.set_xlabel('x [pixel]')\n",
    "ax2.set_ylabel('y [pixel]')\n",
    "ax2.imshow(rateints.data[0], vmin=0, vmax=20)\n",
    "fig.colorbar(ax=ax2, label='DN/s')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, the image looks much cleaner now, and our interpolated replacements are likely to be close to the true values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Background Subtraction <a class=\"anchor\" id=\"background_subtraction\"></a>\n",
    "\n",
    "Here, we will perform a background subtraction using a model/template of the dispersed zodiacal background which we can estimate a scaling factor to scale the template by and subtract from the science frame to remove the background structure. The SOSS background model can be found and downloaded [here](https://stsci.app.box.com/s/9qohomufvzf84tn4gjawnko11oruq2jw) as it will be required for the next steps.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Notes:</b> \n",
    "JWST pipeline does not automaticallyy perform background subtraction at this time. It's been observed that the background changes from target-to-target thus to remove the background user are encourage to use a background template model which can be scaled and removed from the science frames. \n",
    "</div>\n",
    "\n",
    "\n",
    "Lets, load in the background model and plot the template. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to where a user stores the file. \n",
    "bkg_model_path = \"~/Downloads/model_background256.npy\"\n",
    "bkg_model_path = os.path.expanduser(bkg_model_path)\n",
    "\n",
    "bkg_template = np.load(bkg_model_path)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(np.nan_to_num(rateints.data[0]), vmin=0, vmax=20)\n",
    "plt.title('SOSS Data')\n",
    "plt.ylabel('y [pixel]')\n",
    "plt.xlabel('x [pixel]')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(bkg_template)\n",
    "plt.title('SOSS Sky Background Tempalte')\n",
    "plt.ylabel('y [pixel]')\n",
    "plt.xlabel('x [pixel]')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.title('Horizontal Cross Section: Row 50')\n",
    "plt.plot(bkg_template[50])\n",
    "plt.xlabel('x [pixel]')\n",
    "plt.ylabel('DN/s [pixel]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, were going to define and run a helper function with the intention of estimating the scale factor to scale the template by. This method estimates the scale factor by looking a small cutout region free of the dispersed spectra and centered around where the background intensity jumps. Here we'll extract the subarray between pixel rows 210 to 250, and pixel columns 500 to 800. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background_scaler(image, bkg_model, box_bounds=[210,250,600,800], percentile_range=[0.25, 0.75], plot=False):\n",
    "\n",
    "    # extract subregion of background\n",
    "    iy1, iy2, ix1, ix2 = box_bounds\n",
    "    bkg_postage = image[iy1:iy2, ix1:ix2]\n",
    "    model_bkg_postage = bkg_model[iy1:iy2, ix1:ix2]\n",
    "\n",
    "    # mask the bad pixel and compute ratios\n",
    "    bad_pixels = np.isnan(bkg_postage)\n",
    "    ratio = bkg_postage[~bad_pixels] / model_bkg_postage[~bad_pixels]\n",
    "    ratio = ratio.flatten()\n",
    "\n",
    "    # estiamte the scale factor i.e. the median ratio \n",
    "    idx_sorted = np.argsort(ratio)\n",
    "    npixels = len(ratio)\n",
    "\n",
    "    lower_percentile, upper_percentile = percentile_range\n",
    "\n",
    "    pixel_index = np.arange(len(ratio))\n",
    "\n",
    "    idx_lower = int(npixels*lower_percentile)\n",
    "    idx_upper = int(npixels*upper_percentile)\n",
    "\n",
    "    median_ratio = np.median(ratio[idx_sorted][idx_lower:idx_upper])\n",
    "\n",
    "    if plot:\n",
    "        print('plotting scaling results')\n",
    "        original_pixels = bkg_postage.flatten()\n",
    "        bkg_substracted_pixels = bkg_postage.flatten() - model_bkg_postage.flatten() * median_ratio\n",
    "        non_outliers_original = np.where( (bkg_postage.flatten() < 10.5)&(bkg_postage.flatten() > 1.0))[0]\n",
    "        # Plotting\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "        fontsize = 16\n",
    "\n",
    "        # Plot 1: Background Distrubition ratio\n",
    "        # axes[0].set_title('Background Distrubition')\n",
    "        axes[0].plot(pixel_index, ratio[idx_sorted], label='Background Distribution')\n",
    "        axes[0].plot(pixel_index[idx_lower:idx_upper], ratio[idx_sorted][idx_lower:idx_upper], label=f'{lower_percentile*100} to {upper_percentile*100} Percentile Region')\n",
    "        axes[0].set_xlabel('Pixel index', fontsize=fontsize)\n",
    "        axes[0].set_ylabel('Data / Model', fontsize=fontsize)\n",
    "        axes[0].tick_params(axis='both', labelsize=fontsize)\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Plot 2: Ratio distribution\n",
    "        axes[1].plot(ratio, '.', label='Ratio')\n",
    "        axes[1].plot([0, len(ratio)], [median_ratio, median_ratio], label='Median Ratio')\n",
    "        axes[1].set_xlabel('Pixel index', fontsize=fontsize)\n",
    "        axes[1].set_ylabel('Data / Model', fontsize=fontsize)\n",
    "        axes[1].tick_params(axis='both', labelsize=fontsize)\n",
    "        axes[1].legend()\n",
    "\n",
    "        # Plot 3: Original vs. Corrected Pixels\n",
    "        axes[2].plot(original_pixels[non_outliers_original], label='Original')\n",
    "        axes[2].plot(bkg_substracted_pixels[non_outliers_original], label='Corrected')\n",
    "        axes[2].plot([0,8000], [0,0], c='k')\n",
    "        axes[2].set_xlabel('Pixel Index', fontsize=fontsize)\n",
    "        axes[2].set_ylabel('Pixel Value', fontsize=fontsize)\n",
    "        axes[2].tick_params(axis='both', labelsize=fontsize)\n",
    "        axes[2].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return median_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some diagnostic set plot=True\n",
    "median_ratio = get_background_scaler(rateints.data[0], bkg_template, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method we do a good job removing the background counts by subtracting off the scaled background template, and the pixel values are approximately centered around zero. \n",
    "\n",
    "Lets look at a cross section to compare the before and after Background Subtraction using the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.title('Background Subtraction')\n",
    "plt.plot(rateints.data[0, 25])\n",
    "plt.plot((bkg_template * median_ratio)[25])\n",
    "plt.ylabel('DU/s')\n",
    "plt.ylim(2, 20)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(rateints.data[0, 25])\n",
    "plt.plot(rateints.data[0, 25] - (bkg_template * median_ratio)[25])\n",
    "plt.xlabel('x [pixel]')\n",
    "plt.ylabel('DU/s')\n",
    "plt.ylim(-2, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well we do to remove the background from the actual images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_corrected_frames = rateints.data - bkg_template * median_ratio\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(211)\n",
    "plt.title('Before Background Subtraction')\n",
    "plt.imshow(np.log1p(np.nan_to_num(rateints.data[0])), vmin=-1, vmax=3)\n",
    "plt.colorbar()\n",
    "plt.subplot(212)\n",
    "plt.title('After Background Subtraction')\n",
    "plt.imshow(np.log1p(np.nan_to_num(bkg_corrected_frames[0])), vmin=-1.5, vmax=3)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good. Our method to remove the background by scaling a templace of the background structure is effectively removed from the science image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Spectral Tracing <a class=\"anchor\" id=\"tracing\"></a>\n",
    "\n",
    "To trace the spectrum one would need to apply methods such as centroiding, cross correlation, modeling, and so on. Furthermore, SOSS observations are susceptible to rotations and shifts of the positions of dispersed spectral orders on the the detector which is dependent on the position of the pupil wheel that houses the GR700XD which slightly overshoots/undershoots its commanded position. As a result, this impacts the spectral trace positions and wavelength solution observation to observation. To remedy this, a tool was recently released called [PASTASOSS](https://github.com/spacetelescope/pastasoss) (Predicting Accurate Spectral Traces for Astrophysical SOSS Spectra) to predict the spectral trace positions for any niriss SOSS observations given its PWCPOS value. We will be using PASTASOSS to acquire the trace positions for the spectral orders 1 and 2.\n",
    "\n",
    "To use PASTASOSS and get the spectral traces for orders 1 and 2, we need to extract the pupil wheel position angle PWCPOS from the header information. We can find this information by doing a search on the datamodel using the keyword `pupil_position`. Once we know the value we can use the `get_soss_traces()` method in the PASTASOSS package to predict the spectral traces positions and their corresponding wavelength values. At this time, the software fully supports order 1, partial support for order 2 and will support order 3 in the future. \n",
    "\n",
    "<!-- <div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> PASTASOSS supports order 1 fully and partially for order 2.  \n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateints.search('pupil_position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwcpos = rateints.meta.instrument.pupil_position\n",
    "\n",
    "traces_order1, traces_order2, _ = pastasoss.get_soss_traces(pwcpos, order=\"123\", interp=True)\n",
    "\n",
    "print(f\"PWCPOS: {pwcpos} deg\")\n",
    "print(traces_order1)\n",
    "print(traces_order2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASTASOSS outputs a `TraceModel` object which encapsulate the spectral trace infomation for a given order. \n",
    "\n",
    "Let's plot the data with traces positions for the corresponding pupil position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.nan_to_num(bkg_corrected_frames[0]), vmin=0, vmax=10)\n",
    "plt.plot(traces_order1.x, traces_order1.y, color='cornflowerblue', lw=3, label='Order 1')\n",
    "plt.plot(traces_order2.x, traces_order2.y, color='orangered', lw=3, label='Order 2')\n",
    "plt.ylabel('y [pixel]')\n",
    "plt.xlabel('x [pixel]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good! One could measure the spectral traces and perform their own wavelength calibration, however, by using PASTASOSS we can quickly predict the postions and wavelength with sub-pixel accuracy for any NIRISS/SOSS observations. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Notes:</b> \n",
    "PASTASOSS will provide full support for order 2 providing a full trace and improved wavelength solution in a future release along with an update to this notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Remove 1/f noise from the 2D cutouts <a class=\"anchor\" id=\"1overf\"></a>\n",
    "\n",
    "JWST detector readout electronics (aka SIDECAR ASICs) generate significant 1/f noise during detector operations and signal digitization. When using NIRISS, this 1/f noise appears as vertical banding that spans the entire width of the 2D spectral image, and varies from column to column. If not handled properly, the 1/f noise can introduce systematic errors and extra scatter in the light curves. For more information, please visit: <a href=\"https://jwst-docs.stsci.edu/methods-and-roadmaps/jwst-time-series-observations/jwst-time-series-observations-noise-sources#JWSTTimeSeriesObservationsNoiseSources-1/fnoise\">JWST Time-Series Observations Noise Sources.</a>\n",
    "\n",
    "One way to estimate and remove 1/f noise for the SOSS data is to measure the median count level of a column using pixels outside of the Point Spread Function (PSF). This median flux is then subtracted from the entire column. The function below performs this task for a given image using background region above and below the spectrum using the traces we just defined. \n",
    "\n",
    "We'll begin by defining a helper function to perform the 1/f noise removal for a single segmented datast. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_1f(median_frame, frame, x, y, min_bkg=25, max_bkg=35, mask=None, \n",
    "               scale_factor=1., return_1f = False):\n",
    "    \"\"\"Method to perform 1/f noise removal that performs a median integration\n",
    "    frame subtraction to remove the signal to isolate and remove 1/f noise.\"\"\" \n",
    "    new_frame = np.copy(frame)\n",
    "    ms = frame - median_frame * scale_factor\n",
    "\n",
    "    if return_1f:\n",
    "        one_over_f = np.zeros(len(x))\n",
    "    \n",
    "    # Go column-by-column substracting values around the trace:\n",
    "    for i in range(len(x)):\n",
    "        column = int(x[i])\n",
    "        row = int(y[i])\n",
    "        min_row = np.max([0, row - max_bkg])\n",
    "        max_row = np.min([256, row + max_bkg])\n",
    "        bkg = np.append(ms[min_row:row-min_bkg, column], ms[row+min_bkg:max_row, column])\n",
    "        new_frame[:, column] = new_frame[:, column] - np.nanmedian(bkg)\n",
    "        \n",
    "        if return_1f:\n",
    "            one_over_f[i] = np.nanmedian(bkg)\n",
    "        \n",
    "    if return_1f:\n",
    "        return one_over_f, new_frame \n",
    "    else:\n",
    "        return new_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can check if the a transit is present, however, since we are only looking at the first segmented dataset we will observe the relative flux of the out-of-tranist. This is import for our 1/f correction step as we'll need to scale the median frame to remove the underlining signal to better isolate the 1/f noise. This step will be repeat in a later section when we use all the data and see the entire tranist lightcurve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postage = rateints.data[:, 20:60, 1500:1550]\n",
    "timeseries = np.sum(postage, axis = (1,2))\n",
    "\n",
    "# Create smoothed version to use for background + 1/f corrections:\n",
    "smoothed_petit_transit = signal.medfilt(timeseries / np.median(timeseries[0:80]), 11)\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "plt.plot(timeseries / np.median(timeseries[0:80]), '.', color = 'orangered')\n",
    "plt.plot(smoothed_petit_transit, '-', color = 'cornflowerblue')\n",
    "\n",
    "plt.xlim(0, len(timeseries))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('Relative flux', fontsize = 18)\n",
    "plt.xlabel('Integration number', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets run the function and see how the data change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_corrected_median_oot = np.median(bkg_corrected_frames, axis=0)\n",
    "\n",
    "# remove 1/f noise and scale median frame using relative flux\n",
    "one_over_f, new_frame = correct_1f(bkg_corrected_median_oot, \n",
    "                                   bkg_corrected_frames[0], \n",
    "                                   traces_order1.x,\n",
    "                                   traces_order1.y, \n",
    "                                   scale_factor = smoothed_petit_transit[0], \n",
    "                                   return_1f = True)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.title('SCI: UNCORRECTED')\n",
    "im = plt.imshow(rateints.data[0])\n",
    "im.set_clim(-1,10)\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.title('SCI: BACKGROUND REMOVED')\n",
    "im = plt.imshow(bkg_corrected_frames[0])\n",
    "im.set_clim(-1,3)\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.title('SCI: BACKGROUND + 1/f REMOVED')\n",
    "im = plt.imshow(new_frame)\n",
    "im.set_clim(-1,3)\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.title('1/f NOISE')\n",
    "im = plt.imshow(bkg_corrected_frames[0] - new_frame)\n",
    "im.set_clim(-1,1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this is a much more subtle effect than the background, however, the 1/f correction seems to have done a decent job at identifying the banding across the columns. The impact of 1/f noise is likely to change from dataset to dataset, particularly as a function of the number of groups within your integrations, or how heavily the detector is exposed. \n",
    "\n",
    "Potential improvements could be made with more sophisticated techniques, such as: performing 1/f subtraction at the group level prior to the generation of the *rateints.fits files, using a more explicit mask to identify unilluminated pixels, or performing a polynomial fit rather than using the median estimate of the 1/f in each column. However, we do not explore such techniques for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Spectral Extraction <a class=\"anchor\" id=\"extraction\"></a>\n",
    "\n",
    "Now that we have obtain the spectral traces and cleaned the data, we can proceed with the spectral extraction. For this task, we will use a simple aperture extraction to acquire the order 1 and order 2 spectra. However, the JWST pipeline uses [ATOCA](https://ui.adsabs.harvard.edu/abs/2022PASP..134i4502D/abstract) a complex spectral extraction algorithm specifically developed for NIRISS/SOSS data. ATOCA is a complex algorithm that enables simultaneously extraction of the spectral orders as well as disentangling signal from the order 1 and 2 which overlap slightly over a short range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_extraction(image, x, y, aperture_radius, background_radius=50, error_image=None, correct_bkg=True, method = 'sum'):\n",
    "    \"\"\"\n",
    "    This function takes as inputs two arrays (x,y) that follow the trace,\n",
    "    and returns the added flux over the defined aperture radius (and its error, if an error image\n",
    "    is given as well), substracting in the way any background between the aperture radius and the\n",
    "    background radius. The background is calculated by taking the median of the points between the\n",
    "    aperture_radius and the background_radius.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: ndarray\n",
    "        Image from which the spectrum wants to be extracted\n",
    "    x: ndarray\n",
    "        Array with the x-axis of the trace (i.e., the columns, wavelength direction)\n",
    "    y: ndarray\n",
    "        Array with the y-axis of the trace (i.e., rows, spatial direction)\n",
    "    aperture_radius: float\n",
    "        Distance from the center of the trace at which you want to add fluxes.\n",
    "    background_radius: float\n",
    "        Distance from the center of the trace from which you want to calculate the background. The\n",
    "        background region will be between this radius and the aperture_radius.\n",
    "    error_image: ndarray\n",
    "        Image with the errors of each pixel value on the image ndarray above\n",
    "    correct_bkg: boolean\n",
    "        If True, apply background correction. If false, ommit this.\n",
    "    method : string\n",
    "        Method used to perform the extraction. Default is `sum`; `average` takes the average of the non-fractional pixels \n",
    "        used to extract the spectrum. This latter one is useful if the input is a wavelength map.\n",
    "    \"\"\"\n",
    "\n",
    "    method = method.lower()\n",
    "\n",
    "    # If average method being used, remove background correction:\n",
    "    if method == 'average':\n",
    "        correct_bkg = False\n",
    "\n",
    "    # Create array that will save our fluxes:\n",
    "    flux = np.zeros(len(x))\n",
    "    if error_image is not None:\n",
    "        flux_error = np.zeros(len(x))\n",
    "    max_column = image.shape[0] - 1\n",
    "\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        # Cut the column with which we'll be working with:\n",
    "        column = image[:,int(x[i])]\n",
    "        if error_image is not None:\n",
    "            variance_column = error_image[:,int(x[i])]**2\n",
    "\n",
    "        # Define limits given by the aperture_radius and background_radius variables:\n",
    "        if correct_bkg:\n",
    "            left_side_bkg = np.max([y[i] - background_radius, 0])\n",
    "            right_side_bkg = np.min([max_column, y[i] + background_radius])\n",
    "        left_side_ap = np.max([y[i] - aperture_radius, 0])\n",
    "        right_side_ap = np.min([max_column, y[i] + aperture_radius])\n",
    "\n",
    "        # Extract background, being careful with edges:\n",
    "        if correct_bkg:\n",
    "            bkg_left = column[np.max([0, int(left_side_bkg)]) : np.max([0, int(left_side_ap)])]\n",
    "            bkg_right = column[np.min([int(right_side_ap), max_column]) : np.max([int(right_side_bkg), max_column])]\n",
    "            bkg = np.median(np.append(bkg_left, bkg_right))\n",
    "        else:\n",
    "            bkg = 0.\n",
    "\n",
    "        # Substract it from the column:\n",
    "        column -= bkg\n",
    "\n",
    "        # Perform aperture extraction of the background-substracted column, being careful with pixelization\n",
    "        # at the edges. First, deal with left (up) side:\n",
    "        l_decimal, l_integer = np.modf(left_side_ap)\n",
    "        l_integer = int(l_integer)\n",
    "        if l_decimal < 0.5:\n",
    "            l_fraction = (0.5 - l_decimal) * column[np.min([l_integer, max_column])]\n",
    "            l_limit = l_integer + 1\n",
    "            if error_image is not None:\n",
    "                l_fraction_variance = ((0.5 - l_decimal)**2) * variance_column[np.min([l_integer, max_column])]\n",
    "        else:\n",
    "            l_fraction = (1. - (l_decimal - 0.5)) * column[np.min([l_integer + 1, max_column])]\n",
    "            l_limit = l_integer + 2\n",
    "            if error_image is not None:\n",
    "                l_fraction_variance = ((1. - (l_decimal - 0.5))**2) * variance_column[np.min([l_integer + 1, max_column])]\n",
    "\n",
    "        # Now right (down) side:\n",
    "        r_decimal, r_integer = np.modf(right_side_ap)\n",
    "        r_integer = int(r_integer)\n",
    "        if r_decimal < 0.5:\n",
    "            r_fraction = (1. - (0.5 - r_decimal)) * column[np.min([max_column, r_integer])]\n",
    "            r_limit = r_integer\n",
    "            if error_image is not None:\n",
    "                r_fraction_variance = ((1. - (0.5 - r_decimal))**2) * variance_column[np.min([max_column, r_integer])]\n",
    "        else:\n",
    "            r_fraction = (r_decimal - 0.5) * column[np.min([max_column, r_integer + 1])]\n",
    "            r_limit = r_integer + 1\n",
    "            if error_image is not None:\n",
    "                r_fraction_variance = ((r_decimal - 0.5)**2) * variance_column[np.min([max_column, r_integer + 1])]\n",
    "\n",
    "        # Save total flux in current column:\n",
    "        if method == 'sum':\n",
    "            flux[i] = l_fraction + r_fraction + np.sum(column[l_limit:r_limit])\n",
    "\n",
    "        elif method == 'average':\n",
    "            flux[i] = np.mean(column[l_limit:r_limit])\n",
    "\n",
    "        else:\n",
    "            raise Exception('Method \"'+method+'\" currently not supported for aperture extraction. Select either \"sum\" or \"average\".')\n",
    "\n",
    "        if error_image is not None:\n",
    "            # Total error is the sum of the variances:\n",
    "            flux_error[i] = np.sqrt(np.sum(variance_column[l_limit:r_limit]) + l_fraction_variance + \\\n",
    "                                    r_fraction_variance)\n",
    "    if error_image is not None:\n",
    "        return flux, flux_error\n",
    "    else:\n",
    "        return flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare the spectra before and after the background correction step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_order1 = simple_extraction(np.nan_to_num(rateints.data[0]), traces_order1.x, traces_order1.y, aperture_radius=15)\n",
    "spectrum_order2 = simple_extraction(np.nan_to_num(rateints.data[0]), traces_order2.x, traces_order2.y, aperture_radius=15)\n",
    "\n",
    "spectrum_order1_clean = simple_extraction(new_frame, traces_order1.x, traces_order1.y, aperture_radius=15)\n",
    "spectrum_order2_clean = simple_extraction(new_frame, traces_order2.x, traces_order2.y, aperture_radius=15)\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "# plot order 1 spectra\n",
    "plt.subplot(311)\n",
    "plt.title('Order 1')\n",
    "plt.xlabel('Wavelength [$\\mu m$]')\n",
    "plt.ylabel('ADU/s')\n",
    "plt.plot(traces_order1.wavelength, spectrum_order1, label='Before')\n",
    "plt.plot(traces_order1.wavelength, spectrum_order1_clean, label='After')\n",
    "plt.legend()\n",
    "\n",
    "# plot order 2 spectra\n",
    "plt.subplot(312)\n",
    "plt.title('Order 2')\n",
    "plt.xlabel('Wavelength [$\\mu m$]')\n",
    "plt.ylabel('ADU/s')\n",
    "plt.plot(traces_order2.wavelength, spectrum_order2, label='Before')\n",
    "plt.plot(traces_order2.wavelength, spectrum_order2_clean, label='After')\n",
    "\n",
    "# plot difference or ratio\n",
    "plt.subplot(313)\n",
    "plt.xlabel('Wavelength [$\\mu m$]')\n",
    "plt.ylabel('Difference')\n",
    "plt.plot(traces_order1.wavelength, spectrum_order1-spectrum_order1_clean, 'b', label='Order 1')\n",
    "plt.legend(loc='upper left')\n",
    "plt.twiny()\n",
    "plt.plot(traces_order2.wavelength, spectrum_order2-spectrum_order2_clean, 'r', label='Order 2')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(-2, 5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good. There's not much of a significant change in the spectra, however, some underlying structure has been removed.\n",
    "\n",
    "Also notice the 'bumps' in order 2, this is the result of contamination from the zeroth order of field stars, which can also be seen in the 2D images. We do not perform any special treatment for these zero orders here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Generating Lightcurves  <a class=\"anchor\" id=\"lightcurve\"></a>\n",
    "\n",
    "Now lets put everything we've done so far together and generate some lightcurves. So far we've just been using the first segment of our data files, so lets now load in all the data and rerun what we've done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tso_images = []\n",
    "err_images = []\n",
    "all_times = []\n",
    "all_pwcpos = []\n",
    "\n",
    "for file in files:  \n",
    "    print(file.split('/')[-1])\n",
    "    # load the file and extract relavent data \n",
    "    with datamodels.open(rateints_data_folder + file) as tso_data:\n",
    "        data = tso_data.data\n",
    "        err = tso_data.err\n",
    "        pwcpos = tso_data.meta.instrument.pupil_position\n",
    "        times = tso_data.int_times.int_mid_BJD_TDB\n",
    "\n",
    "        tso_images.append(data)\n",
    "        err_images.append(err)\n",
    "        all_pwcpos.append(pwcpos)\n",
    "        all_times.append(times)\n",
    "\n",
    "tso_images = np.vstack(tso_images)\n",
    "err_images = np.vstack(err_images)\n",
    "all_times = np.hstack(all_times)\n",
    "all_pwcpos = np.array(all_pwcpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tso_images.shape, all_times.shape, all_pwcpos.shape, err_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the bad pixel in all the images. This may take some time  ~ 5-min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_bad_pixels = False\n",
    "\n",
    "if replace_bad_pixels:\n",
    "    kernel = Gaussian2DKernel(3, 3)\n",
    "    for i, image in enumerate(tso_images):\n",
    "        tso_images[i] = interpolate_replace_nans(image, kernel)\n",
    "else:\n",
    "    tso_images = np.nan_to_num(tso_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Checking PWCPOS is consistent around files: {np.unique(all_pwcpos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the traces once again using PASTASOSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwcpos = np.unique(all_pwcpos)[0]\n",
    "\n",
    "traces_order1, traces_order2, _ = pastasoss.get_soss_traces(pwcpos, interp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get a quick glimpse of what our light curve looks like before any sort of background or 1/f correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postage = np.nan_to_num(tso_images[:, 20:60, 1500:1550])\n",
    "timeseries = np.sum(postage, axis = (1,2))\n",
    "smoothed_petit_transit = ndimage.median_filter(timeseries / np.median(timeseries[0:80]), 11)\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "plt.plot(timeseries / np.median(timeseries[0:80]), '.', color = 'orangered')\n",
    "plt.plot(smoothed_petit_transit, '-', color = 'cornflowerblue')\n",
    "plt.xlim(0, len(timeseries))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "    \n",
    "plt.ylabel('Relative flux', fontsize = 18)\n",
    "plt.xlabel('Integration number', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate a median background corrected image for the out of transit data to be used as our reference for the 1/f correction.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace here integrations before and after transit:\n",
    "int_before_transit = 200\n",
    "int_after_transit = 410\n",
    "\n",
    "bkg_model = bkg_template * median_ratio\n",
    "bkg_corrected_oot_integrations = np.vstack((\n",
    "    tso_images[:int_before_transit, :, :] - bkg_model, \n",
    "    tso_images[int_after_transit:, :, :] - bkg_model)\n",
    "    )\n",
    "\n",
    "bkg_corrected_median_oot = np.nanmedian(bkg_corrected_oot_integrations, axis = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can perform the 1/f correction and extraction across all of the images. This step might take some time ~2 min. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral extraction box size\n",
    "aperture_radius = 15\n",
    "\n",
    "# store results\n",
    "spectra_order1 = []\n",
    "spectra_order2 = []\n",
    "errs_order1 = []\n",
    "errs_order2 = []\n",
    "\n",
    "for image, err, scale in zip(np.nan_to_num(tso_images), err_images, smoothed_petit_transit):\n",
    "    # median_ratio = get_background_scaler(image, bkg_template, plot=False)\n",
    "    bkg_corrected_frame = image - bkg_model\n",
    "    one_over_f, new_frame = correct_1f(bkg_corrected_median_oot, \n",
    "                                       bkg_corrected_frame, \n",
    "                                       traces_order1.x,\n",
    "                                       traces_order1.y, \n",
    "                                       scale_factor = scale, \n",
    "                                       return_1f = True)\n",
    "    \n",
    "    # extract order 1 and order 2 spectra from cleaned images\n",
    "    spectrum_order1, spectrum_err1 = simple_extraction(new_frame, traces_order1.x, traces_order1.y, aperture_radius=15, error_image=err)\n",
    "    spectrum_order2, spectrum_err2 = simple_extraction(new_frame, traces_order2.x, traces_order2.y, aperture_radius=15, error_image=err)\n",
    "\n",
    "    # append results\n",
    "    spectra_order1.append(spectrum_order1)\n",
    "    spectra_order2.append(spectrum_order2)\n",
    "    errs_order1.append(spectrum_err1)\n",
    "    errs_order2.append(spectrum_err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly convert things to arrays where needed. \n",
    "integration_index = np.arange(len(tso_images))\n",
    "spectra_order1 = np.asarray(spectra_order1)\n",
    "spectra_order2  = np.asarray(spectra_order2)\n",
    "errs_order1  = np.asarray(errs_order1)\n",
    "errs_order2  = np.asarray(errs_order2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the collection of extracted 1D spectra for each integration on top of each other. As you can see we have an almost bimodal distribution, where the spectra with more flux are those that are out-of-transit, the spectra with less flux are in-transit, and the smaller number inbetween trace the flux variations at ingress and egress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# plot order 1 spectra\n",
    "plt.subplot(3,1,1)\n",
    "plt.title('Order1 Close-up: In- and Out-of Transit Spectra')\n",
    "plt.xlabel(\"wavelength [$\\mu m$]\")\n",
    "plt.ylabel(\"DN/s\")\n",
    "for spec in spectra_order1:\n",
    "    plt.plot(traces_order1.wavelength,  spec, 'k', alpha=0.05)\n",
    "\n",
    "plt.xlim(1.1, 1.2)\n",
    "plt.ylim(7500, 8250)\n",
    "\n",
    "# plot order 2 spectra\n",
    "plt.subplot(3,1,2)\n",
    "plt.title('Order 2 Close-up: In- and Out-of Transit Spectra')\n",
    "plt.xlabel(\"wavelength [$\\mu m$]\")\n",
    "plt.ylabel(\"DN/s\")\n",
    "for spec in spectra_order2:\n",
    "    plt.plot(traces_order2.wavelength,  spec, 'k', alpha=0.05)\n",
    "plt.xlim(0.7, 0.74)\n",
    "plt.ylim(3200, 3800)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good. As we see removing the background at the integration level is pretty stable. \n",
    "\n",
    "We can also plot a 2D representation of this variation, as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_order1 = (spectra_order1 / np.nanmedian(spectra_order1, 0) - 1) * 1e6 \n",
    "lightcurve_order2 = (spectra_order2 / np.nanmedian(spectra_order2, 0) - 1) * 1e6 \n",
    "\n",
    "# plot the results\n",
    "n_integrations = np.arange(len(lightcurve_order1))\n",
    "\n",
    "vmax = 20000\n",
    "vmin = -15000\n",
    "\n",
    "plt.figure(figsize=(12,8), dpi=187)\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('WASP-39 Order 1 Lightcurves')\n",
    "plt.pcolormesh(traces_order1.wavelength, \n",
    "               n_integrations, \n",
    "               lightcurve_order1, vmin=vmin, vmax=vmax)\n",
    "plt.xlabel(\"Wavelength [$\\mu m$]\")\n",
    "plt.ylabel(\"Integration\")\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('ppm', rotation=270, fontsize = 15)\n",
    "cbar.ax.get_yaxis().labelpad = 15\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('WASP-39 Order 2 Lightcurves')\n",
    "plt.pcolormesh(traces_order2.wavelength, \n",
    "               n_integrations, \n",
    "               lightcurve_order2, vmin=vmin, vmax=vmax)\n",
    "plt.xlabel(\"Wavelength [$\\mu m$]\")\n",
    "plt.ylabel(\"Integration\")\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('ppm', rotation=270, fontsize = 15)\n",
    "cbar.ax.get_yaxis().labelpad = 15\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a clear band where the drops across all wavelengths due to the transit. By taking vertical slices across this plot, we can in turn look at the light curves at a wavelength of interest. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_times_hr = (all_times-np.nanmean(all_times))*24.\n",
    "\n",
    "# temp plot of the lightcurves nestor needs to review this notebook. \n",
    "plot_wavelengths = traces_order1.wavelength[10:-10:500]\n",
    "\n",
    "plt.figure(figsize=(12, 5.5))\n",
    "\n",
    "offset = 40000\n",
    "for wavelength in plot_wavelengths[::-1]:\n",
    "    plt.plot(all_times_hr, lightcurve_order1[:, np.where(traces_order1.wavelength==wavelength)[0]]+offset, label=f'$\\lambda={wavelength:.2f} \\\\ \\mu m$')\n",
    "    offset -= 20000\n",
    "# plt.plot(all_times_hr, lightcurve_order1[:, 100], color='red', marker=\"o\", markersize=2)\n",
    "# plt.plot(all_times_hr, lightcurve_order1[:, 1100], color='green', marker=\"o\", markersize=2)\n",
    "# plt.plot(all_times_hr, lightcurve_order1[:, 2000], color='blue', marker=\"o\", markersize=2)\n",
    "plt.legend(loc='lower right', ncols=2)\n",
    "plt.xlabel('Time since mid-exposure, hr', fontsize=15)\n",
    "plt.ylabel('Normalized flux', fontsize=15)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the out-of-transit flux standard deviation as a function of wavelength. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_order1_std = np.vstack((\n",
    "    lightcurve_order1[:int_before_transit,], \n",
    "    lightcurve_order1[int_after_transit:])\n",
    "    ).std(0)\n",
    "\n",
    "lightcurve_order2_std = np.vstack((\n",
    "    lightcurve_order2[:int_before_transit,], \n",
    "    lightcurve_order2[int_after_transit:])\n",
    "    ).std(0)\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(12,6))#\n",
    "\n",
    "ax1= ax[0]\n",
    "ax1.set_title('Order 1')\n",
    "ax1.plot(traces_order1.wavelength, lightcurve_order1_std)\n",
    "ax1.set_ylabel(\"out-of-transit stddev\")\n",
    "\n",
    "ax2= ax[1]\n",
    "ax2.set_title('Order 2')\n",
    "ax2.plot(traces_order2.wavelength, lightcurve_order2_std)\n",
    "ax2.set_ylabel(\"out-of-transit stddev\")\n",
    "ax2.set_xlabel(r\"wavelength ($\\mu m$)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Concluding remarks<a class=\"anchor\" id=\"remarks\"></a>\n",
    "\n",
    " <!--need to update the special thanks sections.   -->\n",
    "\n",
    "**Need to update**\n",
    "\n",
    "In this notebook, we demonstrated how to obtain light curves and fitting data products starting from the rateints files, and using a step from the JWST pipeline and our custom steps. The saved data products can now be provided to light curve fitting codes for measurements of the physical properties of the exoplanet and obtaining a transmission spectrum. It should be pointed out that the analyses performed here are only a subset of the possible analyses one can perform, and are in no way the final word on _how_ JWST data _should_ be analyzed. This will be solidified more and more as data comes and best practices are established in the current and future cycles.\n",
    "\n",
    "In conclusion, I would like to express my gratitude to the JWST NIRISS team that has supported the creation of this notebook through discussions and testing, which have improved the notebook. In particular, special thanks to the Time-Series Observations Working Group at STScI, including NÃ©stor Espinoza, Leonardo Ubeda, Sarah Kendrew, Elena Manjavacas, Brian Brooks, Mike Reagan, LoÃ¯c Albert, Everett Schlawin, Stephan Birkmann among others. To the NIRCam IDT team for multiple fruitful discussions, including Everett Schlawin, Thomas Beatty, Tom Greene and Jarron Leisenring. To the ERS Transiting Exoplanet team who have provided several venues for discussion and community input. To the several JWST team members, behind the pipeline and the mission itself, including and in no particular order Bryan Hilbert, Armin Rest, Anton Koekemoer, Alicia Canipe, Melanie Clarke, James Muzerolle, Kayli Glidic, Jeff Valenti and Karl Gordon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
