{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095a295c",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_header.png' alt=\"stsci_logo\" width=\"900px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393e357-9d9d-4516-b28d-4d335fad33a0",
   "metadata": {},
   "source": [
    "#  NIRCam Coronagraphy Pipeline Notebook\n",
    "\n",
    "**Authors**: B. Sunnquist, based on the NIRISS/NIRCam imaging notebooks by R. Diaz and B. Hilbert<br>\n",
    "**Last Updated**: February 26, 2025<br>\n",
    "**Pipeline Version**: 1.17.1 (Build 11.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2029f",
   "metadata": {},
   "source": [
    "**Purpose**:<BR>\n",
    "This notebook provides a framework for processing generic Near-Infrared\n",
    "Camera (NIRCam) Coronagraphy data through all three James Webb Space Telescope\n",
    "(JWST) pipeline stages.  Data is assumed to be located in a folder structure\n",
    "following the paths set up below. It should not be necessary to edit\n",
    "any cells other than in the [Configuration](#1.-Configuration) section unless\n",
    "modifying the standard pipeline processing options.\n",
    "\n",
    "**Data**:<BR>\n",
    "This example is set up to use an example dataset from\n",
    "[Program ID](https://www.stsci.edu/jwst/science-execution/program-information)\n",
    "1386 (PI: Sasha Hinkley). \n",
    "The science target is HIP-65426 which is taken using 2 different roll angles in observations 2 and 3. These observations use the DEEP8 readout pattern with 2 integrations per exposure and 15 groups per intergration. The reference psf is HIP-68245 taken in observation 1 using a 9-POINT-CIRCLE dither pattern. This observation uses the MEDIUM8 readout pattern with 2 integrations per exposure and 4 groups per integration. All data is observed on the NRCALONG detector with the SUB320A335R subarray and uses the F444W filter and MASK335R round coronagraphic mask. \n",
    "Example input data to use will be downloaded automatically unless\n",
    "disabled (i.e., to use local files instead).\n",
    "\n",
    "**JWST pipeline version and CRDS context**:<BR>\n",
    "This notebook was written for the calibration pipeline version given \n",
    "above. It sets the CRDS context to the latest context in the JWST \n",
    "Calibration Reference Data System (CRDS) associated with that\n",
    "pipeline version. If you use different pipeline versions or\n",
    "CRDS context, please read the relevant release notes\n",
    "([here for pipeline](https://github.com/spacetelescope/jwst),\n",
    "[here for CRDS](https://jwst-crds.stsci.edu/)) for possibly relevant\n",
    "changes.<BR>\n",
    "\n",
    "**Updates**:<BR>\n",
    "This notebook is regularly updated as improvements are made to the\n",
    "pipeline. Find the most up to date version of this notebook at:\n",
    "https://github.com/spacetelescope/jwst-pipeline-notebooks/\n",
    "\n",
    "**Recent Changes**:<br>\n",
    "Feb 26, 2025: original notebook created<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e92341",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5291c2f1",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "1. [Configuration](#1.-Configuration) \n",
    "2. [Package Imports](#2.-Package-Imports)\n",
    "3. [Demo Mode Setup (ignore if not using demo data)](#3.-Demo-Mode-Setup-(ignore-if-not-using-demo-data))\n",
    "4. [Directory Setup](#4.-Directory-Setup)\n",
    "5. [Detector1 Pipeline](#5.-Detector1-Pipeline)\n",
    "6. [Image2 Pipeline](#6.-Image2-Pipeline)\n",
    "7. [Coron3 Pipeline](#7.-Coron3-Pipeline)\n",
    "8. [Visualize the final psf-subtracted images](#8.-Visualize-the-final-psf-subtracted-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a63d0",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd07d7",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fe58d-f3c5-4aec-8e14-5323eaf786bd",
   "metadata": {},
   "source": [
    "------------------\n",
    "Set basic configuration for runing notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a649d-a0d2-4e3f-ab6d-cf8c26e6ce1d",
   "metadata": {},
   "source": [
    "#### Install dependencies and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c4ca9",
   "metadata": {},
   "source": [
    "To make sure that the pipeline version is compatabile with the steps\n",
    "discussed below and the required dependencies and packages are installed,\n",
    " you can create a fresh conda environment and install the provided\n",
    "`requirements.txt` file:\n",
    "```\n",
    "conda create -n nircam_coronagraphy_pipeline python=3.11\n",
    "conda activate nircam_coronagraphy_pipeline\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Set the basic parameters to use with this notebook. These will affect\n",
    "what data is used, where data is located (if already in disk), and\n",
    "pipeline modules run in this data. The list of parameters are:\n",
    "\n",
    "* demo_mode\n",
    "* directories with data\n",
    "* pipeline modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic import necessary for configuration\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bb14e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note that <code>demo_mode</code> must be set appropriately below.\n",
    "</div>\n",
    "\n",
    "Set <code>demo_mode = True </code> to run in demonstration mode. In this\n",
    "mode this notebook will download example data from the Barbara A.\n",
    "Mikulski Archive for Space Telescopes \n",
    "([MAST](https://mast.stsci.edu/search/ui/#/jwst)) and process it through \n",
    "the pipeline. This will all happen in a local directory unless modified in \n",
    "[Section 3](#3.-Demo-Mode-Setup-(ignore-if-not-using-demo-data)) below. \n",
    "\n",
    "Set <code>demo_mode = False</code> if you want to process your own data\n",
    "that has already been downloaded and provide the location of the data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f87d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for demo_mode, channel, band, data mode directories, and \n",
    "# processing steps.\n",
    "\n",
    "# -----------------------------Demo Mode---------------------------------\n",
    "demo_mode = True\n",
    "\n",
    "if demo_mode:\n",
    "    print('Running in demonstration mode using online example data!')\n",
    "\n",
    "# --------------------------User Mode Directories------------------------\n",
    "# If demo_mode = False, look for user data in these paths\n",
    "if not demo_mode:\n",
    "    # Set directory paths for processing specific data; these will need\n",
    "    # to be changed to your local directory setup (below are given as\n",
    "    # examples)\n",
    "    user_home_dir = os.path.expanduser('~')\n",
    "\n",
    "    # Point to where science observation data are\n",
    "    # Assumes uncalibrated data in <sci_dir>/uncal/ and results in stage1,\n",
    "    # stage2, stage3 directories\n",
    "    sci_dir = os.path.join(user_home_dir, 'PID1386/')\n",
    "\n",
    "# --------------------------Set Processing Steps--------------------------\n",
    "# Individual pipeline stages can be turned on/off here.  Note that a later\n",
    "# stage won't be able to run unless data products have already been\n",
    "# produced from the prior stage.\n",
    "\n",
    "# Science processing\n",
    "dodet1 = True  # calwebb_detector1\n",
    "doimage2 = True  # calwebb_image2\n",
    "docoron3 = True  # calwebb_coron3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070079a",
   "metadata": {},
   "source": [
    "### Set CRDS context and server\n",
    "Before importing <code>CRDS</code> and <code>JWST</code> modules, we need\n",
    "to configure our environment. This includes defining a CRDS cache\n",
    "directory in which to keep the reference files that will be used by the\n",
    "calibration pipeline.\n",
    "\n",
    "If the root directory for the local CRDS cache directory has not been set\n",
    "already, it will be set to create one in the home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------Set CRDS context and paths----------------------\n",
    "\n",
    "# Each version of the calibration pipeline is associated with a specific CRDS\n",
    "# context file. The pipeline will select the appropriate context file behind\n",
    "# the scenes while running. However, if you wish to override the default context\n",
    "# file and run the pipeline with a different context, you can set that using\n",
    "# the CRDS_CONTEXT environment variable. Here we show how this is done,\n",
    "# although we leave the line commented out in order to use the default context.\n",
    "# If you wish to specify a different context, uncomment the line below.\n",
    "#%env CRDS_CONTEXT jwst_1293.pmap\n",
    "\n",
    "# Check whether the local CRDS cache directory has been set.\n",
    "# If not, set it to the user home directory\n",
    "if (os.getenv('CRDS_PATH') is None):\n",
    "    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n",
    "# Check whether the CRDS server URL has been set.  If not, set it.\n",
    "if (os.getenv('CRDS_SERVER_URL') is None):\n",
    "    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n",
    "\n",
    "# Echo CRDS path in use\n",
    "print(f\"CRDS local filepath: {os.environ['CRDS_PATH']}\")\n",
    "print(f\"CRDS file server: {os.environ['CRDS_SERVER_URL']}\")\n",
    "if os.getenv('CRDS_CONTEXT'):\n",
    "    print(f\"CRDS CONTEXT: {os.environ['CRDS_CONTEXT']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd10c54",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575588c8",
   "metadata": {},
   "source": [
    "## 2. Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the entire available screen width for this notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f7f54-ff98-428b-9fa9-b39c50210c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic system utilities for interacting with files\n",
    "# ----------------------General Imports------------------------------------\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# To display full ouptut of cell, not just the last result\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# -----------------------Astropy/Astroquery Imports--------------------------------\n",
    "# for viewing astropy images and tables\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "# for downloading demo files\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# ------------ Pipeline and  Visualization Imports -----------------------\n",
    "# for visualizing images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for JWST calibration pipeline\n",
    "import jwst\n",
    "import crds\n",
    "\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Image2Pipeline\n",
    "from jwst.pipeline import Coron3Pipeline\n",
    "\n",
    "# JWST pipeline utilities\n",
    "from jwst import datamodels\n",
    "from jwst.associations import asn_from_list  # Tools for creating association files\n",
    "from jwst.associations.lib.rules_level3 import Asn_Lv3NRCCoron  # Definition of a Lvl3 association file\n",
    "\n",
    "# Echo pipeline version and CRDS context in use\n",
    "print(f\"JWST Calibration Pipeline Version: {jwst.__version__}\")\n",
    "print(f\"Using CRDS Context: {crds.get_context_name('jwst')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844d476-f8b3-4c24-9c79-091d6016314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer to keep track of runtime\n",
    "time0 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea709b51",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8050f",
   "metadata": {},
   "source": [
    "## 3. Demo Mode Setup (ignore if not using demo data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96f182c-cf63-4f82-b5a7-0285be9c21e3",
   "metadata": {},
   "source": [
    "------------------\n",
    "If running in demonstration mode, set up the program information to\n",
    "retrieve the uncalibrated data automatically from MAST using\n",
    "[astroquery](https://astroquery.readthedocs.io/en/latest/mast/mast.html).\n",
    "MAST allows for flexibility of searching by the proposal ID and the\n",
    "observation ID instead of just filenames.<br>\n",
    "\n",
    "We will download data from\n",
    "[Program ID](https://www.stsci.edu/jwst/science-execution/program-information)\n",
    "1386 (PI: Sasha Hinkley). \n",
    "The science target is HIP-65426 which is taken using 2 different roll angles in observations 2 and 3 (2 total uncal files). The reference psf is HIP-68245 taken in observation 1 using a 9-POINT-CIRCLE dither pattern (9 total uncal files). All data is observed on the NRCALONG detector with the SUB320A335R subarray and uses the F444W filter and MASK335R round coronagraphic mask.\n",
    " \n",
    "More information about the JWST file naming conventions can be found at:\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/file_naming.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d595f1e-2590-4f01-bb92-13bb43a22b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the program information and paths for demo program\n",
    "if demo_mode:\n",
    "    print('Running in demonstration mode and will download example data from MAST!')\n",
    "    program = \"01386\"\n",
    "    \n",
    "    data_dir = os.path.join('.', 'nrc_coron_demo_data')\n",
    "    download_dir = data_dir\n",
    "    sci_dir = data_dir\n",
    "    uncal_dir = os.path.join(sci_dir, 'uncal')\n",
    "\n",
    "    # Ensure filepaths for input data exist\n",
    "    if not os.path.exists(uncal_dir):\n",
    "        os.makedirs(uncal_dir)\n",
    "        \n",
    "    # Create directory if it does not exist\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674a8b8",
   "metadata": {},
   "source": [
    "Identify list of science (SCI) uncalibrated files associated with visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3a9a7-f946-4f90-8f4f-3ff0904c0f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list of observation IDs for the specified demo program\n",
    "if demo_mode:\n",
    "    sci_obs_id_table = Observations.query_criteria(instrument_name=[\"NIRCAM/CORON\"],\n",
    "                                                   proposal_id=program,\n",
    "                                                   filters=['F444W']\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b7dec-3b0d-4a38-a4b3-2cae5dde9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "if demo_mode:\n",
    "    sci_obs_id_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the list of visits into a list of uncalibrated data files\n",
    "if demo_mode:\n",
    "    # Define types of files to select\n",
    "    file_dict = {'uncal': {'product_type': 'SCIENCE',\n",
    "                           'productSubGroupDescription': 'UNCAL',\n",
    "                           'filters': 'F444W;MASKRND',\n",
    "                           'calib_level': [1]}}\n",
    "\n",
    "    # Science files\n",
    "    sci_files_to_download = []\n",
    "    # Loop over visits identifying uncalibrated files that are associated with them\n",
    "    for exposure in (sci_obs_id_table):\n",
    "        products = Observations.get_product_list(exposure)\n",
    "        for filetype, query_dict in file_dict.items():\n",
    "            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n",
    "                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n",
    "                                                             filters=query_dict['filters'],\n",
    "                                                             calib_level=query_dict['calib_level'])\n",
    "            sci_files_to_download.extend(filtered_products['dataURI'])\n",
    "    sci_files_to_download = sorted(sci_files_to_download)\n",
    "    print(f\"Science files selected for downloading: {len(sci_files_to_download)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1e7d5-4f12-47f0-b43e-764c37943644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the files to download\n",
    "if demo_mode:\n",
    "    sci_files_to_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a54be",
   "metadata": {},
   "source": [
    "Download all the uncal files and place them into the appropriate\n",
    "directories.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Warning: If this notebook is halted during this step the downloaded file\n",
    "may be incomplete, and cause crashes later on!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fa682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download the demo data if it does not already exist\n",
    "if demo_mode:\n",
    "    for filename in sci_files_to_download:\n",
    "        sci_manifest = Observations.download_file(filename,\n",
    "                                                  local_path=os.path.join(uncal_dir, Path(filename).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a7c4f",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c51254-6295-4f98-bc25-d07300e0d8f4",
   "metadata": {},
   "source": [
    "## 4. Directory Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2740f-925d-4139-93f7-9f00cb9820b8",
   "metadata": {},
   "source": [
    "------------------\n",
    "Set up detailed paths to input/output stages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbedc3-fbe3-4c56-ad18-85b5d0c7d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output subdirectories to keep science data products organized\n",
    "uncal_dir = os.path.join(sci_dir, 'uncal')  # Uncalibrated pipeline inputs should be here\n",
    "det1_dir = os.path.join(sci_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\n",
    "image2_dir = os.path.join(sci_dir, 'stage2')  # calwebb_image2 pipeline outputs will go here\n",
    "coron3_dir = os.path.join(sci_dir, 'stage3')  # calwebb_coron3 pipeline outputs will go here\n",
    "\n",
    "# We need to check that the desired output directories exist, and if not create them\n",
    "if not os.path.exists(det1_dir):\n",
    "    os.makedirs(det1_dir)\n",
    "if not os.path.exists(image2_dir):\n",
    "    os.makedirs(image2_dir)\n",
    "if not os.path.exists(coron3_dir):\n",
    "    os.makedirs(coron3_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd878a40-6a3d-41a9-ac22-b09f87f29733",
   "metadata": {},
   "source": [
    "Look at the first file to determine exposure parameters and practice using\n",
    "JWST datamodels to show basic exposure information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae559e7-3d83-41b5-afcd-f0cf53248eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List uncal files\n",
    "uncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n",
    "\n",
    "colnames = ('Instrument', 'Filter', 'Pupil', 'Number of Integrations', 'Number of Groups',\n",
    "            'Readout pattern', 'Dither position number')\n",
    "dtypes = ('S7', 'S10', 'S10', 'i4', 'i4', 'S15', 'i4')\n",
    "meta_check = Table(names=(colnames), dtype=dtypes)\n",
    "\n",
    "# Open example files and get metadata for display\n",
    "if len(uncal_files) > 0:\n",
    "    lw_examine = datamodels.open(uncal_files[0])\n",
    "    lw_row = [lw_examine.meta.instrument.name, lw_examine.meta.instrument.filter,\n",
    "              lw_examine.meta.instrument.pupil, lw_examine.meta.exposure.nints,\n",
    "              lw_examine.meta.exposure.ngroups, lw_examine.meta.exposure.readpatt,\n",
    "              lw_examine.meta.dither.position_number]\n",
    "    meta_check.add_row(lw_row)\n",
    "\n",
    "# Print out exposure info\n",
    "meta_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843ff7f-58b6-4294-bfaa-606c29abc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time_det1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time_det1 - time0:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac2959",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e28e0-a63f-4790-b8a0-3ad4bff5a167",
   "metadata": {},
   "source": [
    "## 5. Detector1 Pipeline\n",
    "Run the datasets through the\n",
    "[Detector1](https://jwst-docs.stsci.edu/jwst-science-calibration-pipeline-overview/stages-of-jwst-data-processing/calwebb_detector1)\n",
    "stage of the pipeline to apply detector level calibrations and create a\n",
    "countrate data product where slopes are fitted to the integration ramps.\n",
    "These `*_rate.fits` products are 2D (nrows x ncols), averaged over all\n",
    "integrations. 3D countrate data products (`*_rateints.fits`) are also\n",
    "created (nintegrations x nrows x ncols) which have the fitted ramp slopes\n",
    "for each integration.\n",
    "\n",
    "By default, all steps in the `Detector1` stage of the pipeline are run for\n",
    "NIRCam except the `ipc` correction step and the `gain_scale` step. Note\n",
    "that the [`persistence` step](https://jwst-pipeline.readthedocs.io/en/latest/jwst/persistence/description.html)\n",
    "has been turned off by default starting with CRDS context `jwst_1264.pmap`.\n",
    "This step does not automatically correct the science data for persistence.\n",
    "The `persistence` step creates a `*_trapsfilled.fits` file which is a model\n",
    "that records the number of traps filled at each pixel at the end of an exposure.\n",
    "This file would be used as an input to the `persistence` step, via the `input_trapsfilled`\n",
    "argument, to correct the subsequent science exposure for persistence. Since persistence\n",
    "is not well calibrated for NIRCam, the step has been turned off in order to speed up\n",
    "calibration and to not create empty `*_trapsfilled.fits` files. This step\n",
    "can be turned on when running the pipeline in Python by doing:\n",
    "```\n",
    "rate_result = Detector1Pipeline.call(uncal, steps={'persistence': {'skip': False}})\n",
    "```\n",
    "or as indicated in the cell bellow using a dictionary.\n",
    "\n",
    "As of CRDS context `jwst_1155.pmap` and later, the \n",
    "[`jump` step](https://jwst-pipeline.readthedocs.io/en/latest/api/jwst.jump.JumpStep.html)\n",
    "of the `Detector1` stage of the pipeline will remove signal associated\n",
    "with [snowballs](https://jwst-docs.stsci.edu/known-issues-with-jwst-data/shower-and-snowball-artifacts)\n",
    "in the NIRCam imaging and coronagraphy modes. This correction is turned on using the parameter\n",
    "`expand_large_events=True`. This and other parameters related to the snowball correction\n",
    "are specified in the `pars-jumpstep` parameter reference file. Users may wish to alter\n",
    "parameters to optimize removal of snowball residuals. Available parameters are discussed\n",
    "in the [Detection and Flagging of Showers and Snowballs in JWST Technical Report (Regan 2023)](https://www.stsci.edu/files/live/sites/www/files/home/jwst/documentation/technical-documents/_documents/JWST-STScI-008545.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592ee58-b424-4bd6-973b-88fd081b81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Detector1 pipeline should be configured\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "det1dict = {}\n",
    "det1dict['group_scale'], det1dict['dq_init'], det1dict['saturation'] = {}, {}, {}\n",
    "det1dict['ipc'], det1dict['superbias'], det1dict['refpix'] = {}, {}, {}\n",
    "det1dict['linearity'], det1dict['persistence'], det1dict['dark_current'], = {}, {}, {}\n",
    "det1dict['charge_migration'], det1dict['jump'], det1dict['clean_flicker_noise'] = {}, {}, {}\n",
    "det1dict['ramp_fit'], det1dict['gain_scale'] = {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped\n",
    "# skipping the persistence step\n",
    "det1dict['persistence']['skip'] = True\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n",
    "#det1dict['saturation']['override_saturation'] = 'myfile.fits'  # Saturation\n",
    "#det1dict['reset']['override_reset'] = 'myfile.fits'  # Reset\n",
    "#det1dict['linearity']['override_linearity'] = 'myfile.fits'  # Linearity\n",
    "#det1dict['rscd']['override_rscd'] = 'myfile.fits'  # RSCD\n",
    "#det1dict['dark_current']['override_dark'] = 'myfile.fits'  # Dark current subtraction\n",
    "#det1dict['jump']['override_gain'] = 'myfile.fits'  # Gain used by jump step\n",
    "#det1dict['ramp_fit']['override_gain'] = 'myfile.fits'  # Gain used by ramp fitting step\n",
    "#det1dict['jump']['override_readnoise'] = 'myfile.fits'  # Read noise used by jump step\n",
    "#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits'  # Read noise used by ramp fitting step\n",
    "\n",
    "# Turn on multi-core processing (This is off by default). Choose what fraction\n",
    "# of cores to use (quarter, half, all, or an integer number)\n",
    "det1dict['jump']['maximum_cores'] = 'half'\n",
    "\n",
    "# Explicitly turn on snowball correction. (Even though it is on by default)\n",
    "det1dict['jump']['expand_large_events'] = True\n",
    "\n",
    "# Turn on 1/f correction if desired\n",
    "# For guidance see https://jwst-docs.stsci.edu/known-issues-with-jwst-data/1-f-noise\n",
    "#det1dict['clean_flicker_noise']['skip'] = False\n",
    "#det1dict['clean_flicker_noise']['fit_method'] = 'median' # 'median' or 'fft'\n",
    "#det1dict['clean_flicker_noise']['background_method'] = 'median' # 'median' or 'model'\n",
    "#det1dict['clean_flicker_noise']['fit_by_channel'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1495ec7-633d-425d-a9e7-cbf9f8a6580d",
   "metadata": {},
   "source": [
    "Run the `Detector1` pipeline on all input data, regardless of filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f107b-5f80-4674-bc34-2d88791e4409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Detector1 stage of pipeline, specifying:\n",
    "# output directory to save *_rate.fits files\n",
    "# save_results flag set to True so the rate files are saved\n",
    "if dodet1:\n",
    "    for uncal in uncal_files:\n",
    "        rate_result = Detector1Pipeline.call(uncal, output_dir=det1_dir, steps=det1dict, save_results=True)\n",
    "else:\n",
    "    print('Skipping Detector1 processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc2b48-7ec7-4b59-b3ee-2dfdf0782c01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n",
    "print(f\"Runtime for Detector1: {time1 - time_det1:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5520a-6097-482b-b3e0-a6bf94cf7af3",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "\n",
    "Identify `*_rateints.fits` files and verify which pipeline steps were run and\n",
    "which calibration reference files were applied.\n",
    "\n",
    "The header contains information about which calibration steps were\n",
    "completed and skipped and which reference files were used to process the\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c122766-a545-4042-93e8-f68c18f62fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dodet1:\n",
    "    # find rate files\n",
    "    rate_files = sorted(glob.glob(os.path.join(det1_dir, '*_rateints.fits')))\n",
    "\n",
    "    # Read in file as datamodel\n",
    "    rate_f = datamodels.open(rate_files[0])\n",
    "\n",
    "    # Check which steps were run\n",
    "    rate_f.meta.cal_step.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2396cc-939f-44a6-878c-b33955796da8",
   "metadata": {},
   "source": [
    "For this particular rate file, show which reference files were used to calibrate the dataset. Note that these files will be different for each NIRCam detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525e133-d875-4ea7-9552-d7f0df05747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dodet1:\n",
    "    rate_f.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf557837",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350808ee-9579-4cb5-8f02-a74904c91449",
   "metadata": {},
   "source": [
    "## 6. Image2 Pipeline \n",
    "\n",
    "In the [Image2 stage of the pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image2.html),\n",
    "calibrated unrectified data products are created (`*_cal.fits` or\n",
    "`*_calints.fits` files, depending on whether the input files are\n",
    "`*_rate.fits` or `*_rateints.fits`). For the coronagraphy pipeline, we use the `_rateints.fits` files as input.\n",
    "\n",
    "In this pipeline processing stage, the [world coordinate system (WCS)](https://jwst-pipeline.readthedocs.io/en/latest/jwst/assign_wcs/index.html#assign-wcs-step)\n",
    "is assigned, the data are [flat fielded](https://jwst-pipeline.readthedocs.io/en/latest/jwst/flatfield/index.html#flatfield-step),\n",
    "and a [photometric calibration](https://jwst-pipeline.readthedocs.io/en/latest/jwst/photom/index.html#photom-step)\n",
    "is applied to convert from units of countrate (ADU/s) to surface brightness (MJy/sr).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a091817-7a3c-4a60-a914-f9ac54d36e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_image2 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00fda2-a7c0-445a-bf23-0d9b4f050419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Image2 pipeline should be configured.\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "image2dict = {}\n",
    "image2dict['assign_wcs'], image2dict['flat_field'] = {}, {}\n",
    "image2dict['photom'], image2dict['resample'] = {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#image2dict['resample']['skip'] = False\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#image2dict['assign_wcs']['override_distortion'] = 'myfile.asdf' # Spatial distortion (ASDF file)\n",
    "#image2dict['assign_wcs']['override_filteroffset'] = 'myfile.asdf' # Imager filter offsets (ASDF file)\n",
    "#image2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf' # Spectral distortion (ASDF file)\n",
    "#image2dict['assign_wcs']['override_wavelengthrange'] = 'myfile.asdf' # Wavelength channel mapping (ASDF file)\n",
    "#image2dict['flat_field']['override_flat'] = 'myfile.fits' # Pixel flatfield\n",
    "#image2dict['photom']['override_photom'] = 'myfile.fits' # Photometric calibration array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247170cd-a3ee-4d9d-b8b3-f930727f8abc",
   "metadata": {},
   "source": [
    "Find and sort all of the input files, ensuring use of absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19cd4e6-cc38-4e26-8e8b-7fb143856940",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstring = os.path.join(det1_dir, 'jw*rateints.fits')  # Use files from the detector1 output folder\n",
    "rate_files = sorted(glob.glob(sstring))\n",
    "rate_files = [os.path.abspath(fname) for fname in rate_files]\n",
    "\n",
    "print(f\"Found  {len(rate_files)} science files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc9789-9048-4c2f-826d-69c36fcd1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List rate files\n",
    "rate_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e93d96-08be-42ac-bb34-8502d199e8ab",
   "metadata": {},
   "source": [
    "Run the Image2 pipeline on all of the rateints files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d916e5-dd5d-472d-9aff-b2b4c86decf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Image2 stage of pipeline, specifying:\n",
    "# output directory to save *_calints.fits files\n",
    "# save_results flag set to True so the calints files are saved\n",
    "\n",
    "if doimage2:\n",
    "    for rate in rate_files:\n",
    "        cal_result = Image2Pipeline.call(rate, output_dir=image2_dir, steps=image2dict, save_results=True)\n",
    "else:\n",
    "    print(\"Skipping Image2 processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58b94d-e1d7-4b73-b598-756c99d81174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n",
    "print(f\"Runtime for Image2: {time1 - time_image2:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da57b7d0-95ef-4227-b730-6f54a3eaaa16",
   "metadata": {},
   "source": [
    "### Verify which pipeline steps were run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27390bbd-ae2d-49e7-977a-59d3765c0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "if doimage2:\n",
    "    # Identify *_cal.fits file products\n",
    "    cal_files = sorted(glob.glob(os.path.join(image2_dir, '*_calints.fits')))\n",
    "\n",
    "    # Select first file to gather information\n",
    "    cal_f = datamodels.open(cal_files[0])\n",
    "\n",
    "    # Check which steps were run:\n",
    "    cal_f.meta.cal_step.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77293ab-4eaa-4ebd-9f9b-bef8f6a2300f",
   "metadata": {},
   "source": [
    "Check which reference files were used to calibrate the first file. Some of these will be detector-dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544744b-804e-4583-8311-e47b5e16c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if doimage2:\n",
    "    cal_f.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159a021",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfbb244-7af9-4cbf-90d9-08598378c16a",
   "metadata": {},
   "source": [
    "## 7. Coron3 Pipeline\n",
    "\n",
    "In the [Coron3 stage of the pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_coron3.html), the `*_calints.fits` files from the reference psf images are aligned and subtracted from the science psf images, and the psf-subtracted science images are combined into a single undistorted product.\n",
    "\n",
    "First, we need to create [Associations](https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/overview.html), to inform the pipeline which files are the reference and science psfs.\n",
    "\n",
    "By default, the `Coron3` stage of the pipeline performs the following steps on NIRCam data: \n",
    "- [outlier_detection](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/index.html#outlier-detection-step) - flags outlier pixels in all input images.\n",
    "- [stack_refs](https://jwst-pipeline.readthedocs.io/en/latest/jwst/stack_refs/index.html#stack-refs-step) - stacks all of the reference psf images together into a single product.\n",
    "- [align_refs](https://jwst-pipeline.readthedocs.io/en/latest/jwst/align_refs/index.html#align-refs-step) - aligns all of the reference psf images to the science target images.\n",
    "- [klip](https://jwst-pipeline.readthedocs.io/en/latest/jwst/klip/index.html#klip-step) - fits and subtracts a psf from each science target image.\n",
    "- [resample](https://jwst-pipeline.readthedocs.io/en/latest/jwst/resample/index.html#resample-step) - combines all of the psf-subtracted science images into a single undistorted product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e81dc9-78dd-4bba-879c-9dfa2a4da69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_coron3 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159e63d-3c89-44ef-9a43-caaccd1abb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Coron3 pipeline should be configured\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "coron3dict = {}\n",
    "coron3dict['outlier_detection'], coron3dict['stack_refs'], coron3dict['align_refs'] = {}, {}, {}\n",
    "coron3dict['klip'], coron3dict['resample'] = {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#coron3dict['outlier_detection']['skip'] = True\n",
    "\n",
    "# Reduce the SNR required for a pixel to be flagged as an outlier\n",
    "#coron3dict['outlier_detection']['snr'] = '4.5 3.5'\n",
    "\n",
    "# Define which pixels types are bad based on the images' data quality arrays \n",
    "# (only DO_NOT_USE by default). New bad pixels can be flagged in the images' data \n",
    "# quality arrays to avoid issues with the psf alignment or subtraction steps.\n",
    "#coron3dict['align_refs']['bad_bits'] = 'DO_NOT_USE, OTHER_BAD_PIXEL'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10da872-21ae-46c2-a3b1-f9cdefae3b36",
   "metadata": {},
   "source": [
    "Find and sort all of the input files, ensuring use of absolute paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b5b47-62e9-4593-abc4-7ec630492e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science Files need the calints.fits files\n",
    "sstring = os.path.join(image2_dir, '*_calints.fits')\n",
    "\n",
    "# Identify calints files\n",
    "cal_files = sorted(glob.glob(os.path.join(image2_dir, '*_calints.fits')))\n",
    "\n",
    "# Expand the relative paths into absolute paths\n",
    "cal_files = [os.path.abspath(fname) for fname in cal_files]\n",
    "\n",
    "print(f'Found {len(cal_files)} science files to process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cb6f5-44a1-4f28-95dc-b23a97451465",
   "metadata": {},
   "source": [
    "### Create Association File\n",
    "\n",
    "An association file lists the files to calibrate together in `Stage3` of the pipeline. For the `Coron3` pipeline, the reference and science psfs must be specified in the association file. Note that association files are available for download from MAST, with filenames of `*_asn.json`. Here we show how to create an association file to point to the data products created in the steps above. This is useful in cases where you want to work with a set of data that is different than that in the association files from MAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6550a4a-f924-410b-a945-effcef431e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of data to use\n",
    "print('\\nList of calints files to use:')\n",
    "cal_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31f80f-8d7b-45ae-8537-15d0208637df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Level 3 Association for the Coron3 pipeline\n",
    "asn_filename = os.path.join(coron3_dir, 'HIP-65426_F444W.json')\n",
    "product_name = 'HIP-65426_F444W'  # name of the final output product\n",
    "asn = asn_from_list.asn_from_list(cal_files, rule=Asn_Lv3NRCCoron, product_name=product_name)\n",
    "for member in asn['products'][0]['members']:  # observations 2 and 3 are the science targets, observation 1 is the reference psf\n",
    "    if fits.getheader(member['expname'])['IS_PSF']:\n",
    "        member['exptype'] = 'psf'\n",
    "    else:\n",
    "        member['exptype'] = 'science'\n",
    "asn.validity['has_psf']['validated'] = True  # set to True since psfs were added to the asn above\n",
    "asn['asn_type'] = 'coron3'\n",
    "with open(asn_filename, 'w') as outfile:\n",
    "    outfile.write(asn.dump()[1])\n",
    "asn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629cad5b-e5a7-473e-8583-ad12cda55fa4",
   "metadata": {},
   "source": [
    "### Run Coron3 stage of the pipeline\n",
    "\n",
    "The `Coron3` stage of the pipeline will produce the following outputs:\n",
    "- a `_crf.fits` file produced by the `outlier_detection` step for each input image, where the `DQ` array marks the pixels flagged as outliers.\n",
    "- a `_psfstack` image containing a stack of all of the reference psf images.\n",
    "- a `_psfalign` image for each science psf, where the reference psfs have been aligned to the science psf.\n",
    "- a `_psfsub` image for each science psf, where the aligned reference psfs have been subtracted from the science psf.\n",
    "- a final combined, undistorted psf-subtracted image with suffix `_i2d.fits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add92ce-d686-43cb-beaf-927d6a027d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Coron3 stage of pipeline, specifying:\n",
    "# output directory to save output files\n",
    "# save_results flag set to True so the files are saved\n",
    "\n",
    "if docoron3:\n",
    "    result = Coron3Pipeline.call(asn_filename, output_dir=coron3_dir, steps=coron3dict, save_results=True)\n",
    "else:\n",
    "    print(\"Skipping Coron3 processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d2c65-4614-4592-aa67-daa2de985013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.0f} seconds\")\n",
    "print(f\"Runtime for Coron3: {time1 - time_coron3:0.0f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb6c40-fbb8-4226-b620-64b0c02c8ceb",
   "metadata": {},
   "source": [
    "### Verify which pipeline steps were run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754530a-d4e2-493b-bf8b-bf8d1ad08770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify *_i2d file and open as datamodel\n",
    "if docoron3:\n",
    "    i2d_file = os.path.join(coron3_dir, f'{product_name}_i2d.fits')\n",
    "    i2d_model = datamodels.open(i2d_file)\n",
    "    step_check_model = i2d_model\n",
    "\n",
    "    # Check which steps were run.\n",
    "    step_check_model.meta.cal_step.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c5280-69a5-4796-b78f-724078a94d2b",
   "metadata": {},
   "source": [
    "Check which reference files were used to calibrate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb20ca7-2e14-4e2e-85fb-33f8ec057716",
   "metadata": {},
   "outputs": [],
   "source": [
    "if docoron3:\n",
    "    step_check_model.meta.ref_file.instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade57bb3",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be5421-7fc8-4d96-b2cd-2484f294e082",
   "metadata": {},
   "source": [
    "## 8. Visualize the final psf subtracted images\n",
    "\n",
    "Below we show each individual psf-subtracted science roll and integration, as well as the final combined psf-subtracted image from the `Coron3` pipeline run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5426a1-3932-4add-8e65-40939a9ee140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the psf-subtracted images generated in the coron3 pipeline run\n",
    "if docoron3:\n",
    "    files = sorted(glob.glob(os.path.join(coron3_dir, '*_psfsub.fits')))\n",
    "    grid = plt.GridSpec(2, 4, hspace=0.3, wspace=0.3)\n",
    "    fig = plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # Plot the psf-subtracted science images for each roll and integration\n",
    "    for roll in range(len(files)):\n",
    "        data = fits.getdata(files[roll])\n",
    "        for integ in range(data.shape[0]):\n",
    "            data_int = data[integ]\n",
    "            ax = fig.add_subplot(grid[roll, integ])\n",
    "            ax.imshow(data_int, vmin=-2, vmax=2, origin='lower', cmap='coolwarm')\n",
    "            ax.set_title('Roll {} Int {}'.format(roll+1, integ+1))\n",
    "    \n",
    "    # Plot the final combined psf-subtracted science image\n",
    "    i2d_file = os.path.join(coron3_dir, f'{product_name}_i2d.fits')\n",
    "    ax = fig.add_subplot(grid[0:2, 2:4])\n",
    "    data = fits.getdata(i2d_file)\n",
    "    ax.imshow(data, vmin=-2, vmax=2, origin='lower', cmap='coolwarm')\n",
    "    ax.set_title('Combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a45cd",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde191a9-cc88-4584-8524-780d245b469f",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_footer.png' alt=\"stsci_logo\" width=\"400px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
