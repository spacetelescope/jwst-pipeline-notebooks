{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df273d4",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src='https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_header.png' alt=\"stsci_logo\" width=\"900px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac9dae",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# MIRI LRS Slit Mode Pipeline Notebook #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281654a3",
   "metadata": {},
   "source": [
    "**Authors**: Ian Wong; MIRI branch<br>\n",
    "**Last Updated**: February 1, 2025<br>\n",
    "**Pipeline Version**: 1.17.1 (Build 11.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1719a7b7",
   "metadata": {},
   "source": [
    "**Purpose**:<BR>\n",
    "This notebook provides a framework for processing generic Mid-Infrared\n",
    "Instrument (MIRI) Low Resolution Spectroscopy (LRS) slit mode data through all\n",
    "three James Webb Space Telescope (JWST) pipeline stages.  The data are assumed\n",
    "to be located in the observation directory located in the path set up below. \n",
    "It should not be necessary to edit any cells other than in the [Configuration](#1.-Configuration) section unless modifying the standard pipeline processing options.\n",
    "\n",
    "**Data**:<BR>\n",
    "This example is set up to use observations of the A-type standard star BD+60 1753, which were obtained as part of the Cycle 1 JWST flux calibration campaign by Proposal ID (PID) 1536 Observation 27. The target is a\n",
    "point source that is dithered within the slit using the standard 2-point along-slit nod pattern. The two dithered observations will be used together to remove the background flux.\n",
    "The example uncalibrated data will be downloaded automatically unless\n",
    "disabled (i.e., to run with user-supplied local files instead).\n",
    "\n",
    "**JWST pipeline version and CRDS context**:<BR>\n",
    "This notebook was written for the\n",
    "calibration pipeline version listed above.  When running with a different pipeline\n",
    "version and/or a non-default reference file context, please see the relevant\n",
    "release notes\n",
    "([here for pipeline](https://github.com/spacetelescope/jwst),\n",
    "[here for CRDS](https://jwst-crds.stsci.edu/)) for possibly relevant\n",
    "changes.<BR>\n",
    "\n",
    "**Updates**:<BR>\n",
    "This notebook is regularly updated as improvements are made to the\n",
    "pipeline. Find the most up to date version of this notebook at:\n",
    "https://github.com/spacetelescope/jwst-pipeline-notebooks/\n",
    "\n",
    "**Recent Changes**:<br>\n",
    "Feb 1 2025: Notebook created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c782a1",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa626805",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Configuration](#1.-Configuration)\n",
    "2. [Package Imports](#2.-Package-Imports)\n",
    "3. [Demo Mode Setup](#3.-Demo-Mode-Setup-(ignore-if-not-using-demo-data))\n",
    "4. [Directory Setup](#4.-Directory-Setup)\n",
    "5. [Detector1 Pipeline](#5.-Detector1-Pipeline)\n",
    "6. [Spec2 Pipeline](#6.-Spec2-Pipeline)\n",
    "7. [Spec3 Pipeline](#7.-Spec3-Pipeline)\n",
    "8. [Plot the spectrum](#8.-Plot-the-spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfdfb3",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c436c2d2",
   "metadata": {},
   "source": [
    "1.<font color='white'>-</font>Configuration<a class=\"anchor\" id=\"intro\"></a>\n",
    "------------------\n",
    "### Install dependencies\n",
    "To make sure that the pipeline version is compatabile with this notebook and the required dependencies and packages are installed,\n",
    "it is recommended that users create a new dedicated conda environment and install the provided\n",
    "`requirements.txt` file before starting this notebook: <br>\n",
    "```\n",
    "conda create -n lrs_demo python=3.11\n",
    "conda activate lrs_demo\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Set run parameters\n",
    "Set basic parameters to use with the notebook. These will affect\n",
    "what observation is used, where the uncalibrated data are located (if already on disk), which\n",
    "pipeline modules to run on the data, and whether background subtraction is carried out. The list of parameters are:\n",
    "\n",
    "* demo_mode\n",
    "* directory with data\n",
    "* pipeline steps\n",
    "* bkg_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ba792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic import necessary for configuration\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c10f09",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note that <code>demo_mode</code> must be set appropriately below.\n",
    "</div>\n",
    "\n",
    "Set <code>demo_mode = True </code> to run in demonstration mode. In this mode, this\n",
    "notebook will download the example data from the\n",
    "Barbara A. Mikulski Archive for Space Telescopes (MAST) and process them through the pipeline.\n",
    "All input and output data will be stored in the local directory unless modified\n",
    "in [Section 3](#3.-Demo-Mode-Setup-(ignore-if-not-using-demo-data)) below. \n",
    "\n",
    "Set <code>demo_mode = False</code> to process user-specified data that have already\n",
    "been downloaded and provide the location of the data.<br>\n",
    "\n",
    "The <code>bkg_sub</code> flag instructs the pipeline whether to carry out nod subtraction (i.e., A-B subtraction) to remove the background flux from each exposure. This is the default treatment for slit mode observations that use the standard nod pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca86088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for demo_mode, data directory, and processing steps\n",
    "\n",
    "# -----------------------------Demo Mode---------------------------------\n",
    "demo_mode = True\n",
    "\n",
    "if demo_mode:\n",
    "    print('Running in demonstration mode using online example data!')\n",
    "\n",
    "# --------------------------User Mode Directories------------------------\n",
    "# If demo_mode = False, look for user data in these paths\n",
    "if not demo_mode:\n",
    "    # Set directory paths for processing specific data; these will need\n",
    "    # to be changed to the user's local directory setup (paths below are given as\n",
    "    # examples).\n",
    "    user_home_dir = os.path.expanduser('~')\n",
    "\n",
    "    # Point to where the observation data are stored.\n",
    "    # Assumes uncalibrated data in sci_dir/uncal/, with results stored in stage1,\n",
    "    # stage2, stage3 directories.\n",
    "    sci_dir = os.path.join(user_home_dir, 'PID01536Obs027/')\n",
    "\n",
    "# --------------------------Set Processing Steps--------------------------\n",
    "# Individual pipeline stages can be turned on/off here.  Note that a later\n",
    "# stage won't be able to run unless data products have already been\n",
    "# produced from the prior stage.\n",
    "\n",
    "# Pipeline processing\n",
    "do_det1  = True  # calwebb_detector1\n",
    "do_spec2 = True  # calwebb_spec2\n",
    "do_spec3 = True  # calwebb_spec3\n",
    "do_viz   = True  # Visualize calwebb_spec3 results\n",
    "\n",
    "# Background subtraction\n",
    "bkg_sub  = True  # Set as true to carry out nod subtraction for background removal (recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb911bb5",
   "metadata": {},
   "source": [
    "### Set CRDS context and server\n",
    "Before importing <code>CRDS</code> and <code>JWST</code> modules, we need to configure our environment. This includes defining a CRDS cache directory in which to keep the reference files that will be used by the calibration pipeline.\n",
    "\n",
    "If the root directory for the local CRDS cache directory has not been set already, it will be automatically created in the home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a610c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------Set CRDS context and paths----------------------\n",
    "# Set CRDS reference file context.  Leave commented out to use the default context\n",
    "# (latest reference files associated with the calibration pipeline version)\n",
    "# or set a specific context here.\n",
    "#%env CRDS_CONTEXT  jwst_1295.pmap\n",
    "\n",
    "# Check whether the local CRDS cache directory has been set.\n",
    "# If not, set it to the user home directory.\n",
    "if (os.getenv('CRDS_PATH') is None):\n",
    "    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds')\n",
    "    \n",
    "# Check whether the CRDS server URL has been set.  If not, set it.\n",
    "if (os.getenv('CRDS_SERVER_URL') is None):\n",
    "    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n",
    "\n",
    "# Print out CRDS path and context that will be used\n",
    "print('CRDS local filepath:', os.environ['CRDS_PATH'])\n",
    "print('CRDS file server:', os.environ['CRDS_SERVER_URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ade3e5",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b202d63",
   "metadata": {},
   "source": [
    "## 2.<font color='white'>-</font>Package Imports<a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a39a9",
   "metadata": {},
   "source": [
    "Automatically import necessary Python packages for use in the data processing and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the entire available screen width for this notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic system utilities for interacting with files\n",
    "# ----------------------General Imports------------------------------------\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Numpy for doing calculations\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------Astropy Imports-----------------------------------\n",
    "# Astropy utilities for opening FITS and ASCII files and downloading demo files\n",
    "from astropy.io import fits\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# -----------------------Plotting Imports----------------------------------\n",
    "# Matplotlib for making plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------JWST Calibration Pipeline Imports---------------------------\n",
    "# Import the base JWST and calibration reference data packages\n",
    "import jwst\n",
    "import crds\n",
    "\n",
    "# JWST pipelines (each encompassing many steps)\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Spec2Pipeline\n",
    "from jwst.pipeline import Spec3Pipeline\n",
    "\n",
    "# JWST pipeline utilities\n",
    "from jwst import datamodels  # JWST datamodels\n",
    "from jwst.associations import asn_from_list as afl  # Tools for creating association files\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase  # Definition of a Lvl2 association file\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base  # Definition of a Lvl3 association file\n",
    "from jwst.stpipe import Step  # Import the wrapper class for pipeline steps\n",
    "\n",
    "# Print out pipeline version and CRDS context that will be used\n",
    "print(\"JWST Calibration Pipeline Version = {}\".format(jwst.__version__))\n",
    "print(\"Using CRDS Context = {}\".format(crds.get_context_name('jwst')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a timer to keep track of runtime\n",
    "time0 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728acd7c",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92329359",
   "metadata": {},
   "source": [
    "3.<font color='white'>-</font>Demo Mode Setup<a class=\"anchor\" id=\"intro\"></a> (ignore if not using demo data)\n",
    "------------------\n",
    "If running in demonstration mode, set up the program information to\n",
    "retrieve the uncalibrated data automatically from MAST using\n",
    "[astroquery](https://astroquery.readthedocs.io/en/latest/mast/mast.html).\n",
    "MAST allows for flexibility of searching by the proposal ID and the\n",
    "observation ID instead of just filenames.<br>\n",
    "\n",
    "More information about the JWST file naming conventions can be found at:\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/file_naming.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61079e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the program information and paths for demo program\n",
    "if demo_mode:\n",
    "    program = \"01536\"\n",
    "    sci_obs = \"027\"\n",
    "    basedir = os.path.join('.', 'lrs_demo_data')\n",
    "    obs_dir = os.path.join(basedir, 'PID' + program + 'Obs' + sci_obs)\n",
    "    uncal_dir = os.path.join(obs_dir, 'uncal')\n",
    "\n",
    "    # Ensure filepath for input data exists\n",
    "    os.makedirs(uncal_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f14935",
   "metadata": {},
   "source": [
    "Identify the list of uncalibrated files associated with the observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list of observation IDs for the specified demo program\n",
    "if demo_mode:\n",
    "    obs_id_table = Observations.query_criteria(instrument_name=[\"MIRI/SLIT\"],\n",
    "                                                   provenance_name=[\"CALJWST\"],  # Executed observations\n",
    "                                                   obs_id=['jw' + program + '-o' + sci_obs + '*']\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9775c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the list of visits into a list of uncalibrated data files\n",
    "if demo_mode:\n",
    "    # Define types of files to select\n",
    "    file_dict = {'uncal': {'product_type': 'SCIENCE', \n",
    "                           'productSubGroupDescription': 'UNCAL', \n",
    "                           'calib_level': [1]}}\n",
    "\n",
    "    # Files to download\n",
    "    files_to_download = []\n",
    "    # Loop over visits, identifying uncalibrated files that are associated with them\n",
    "    for exposure in obs_id_table:\n",
    "        products = Observations.get_product_list(exposure)\n",
    "        for filetype, query_dict in file_dict.items():\n",
    "            filtered_products = Observations.filter_products(products, productType=query_dict['product_type'],\n",
    "                                                             productSubGroupDescription=query_dict['productSubGroupDescription'],\n",
    "                                                             calib_level=query_dict['calib_level'])\n",
    "            files_to_download.extend(filtered_products['dataURI'])\n",
    "\n",
    "    print(\"Number of files selected for downloading: \", len(files_to_download))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e27f1",
   "metadata": {},
   "source": [
    "Download all the uncal files and place them into the appropriate directories.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Warning: If this notebook is halted during this step, the downloaded files may be incomplete and cause crashes later on!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d724787",
   "metadata": {},
   "outputs": [],
   "source": [
    "if demo_mode:\n",
    "    for filename in files_to_download:\n",
    "        obs_manifest = Observations.download_file(filename, local_path=os.path.join(uncal_dir, Path(filename).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be151cf9",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad7e1a0",
   "metadata": {},
   "source": [
    "4.<font color='white'>-</font>Directory Setup<a class=\"anchor\" id=\"intro\"></a>\n",
    "------------------\n",
    "Set up detailed paths to input/output stages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2836fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output subdirectories to keep data products organized\n",
    "uncal_dir = os.path.join(obs_dir, 'uncal')   # Uncalibrated pipeline inputs should be here\n",
    "det1_dir  = os.path.join(obs_dir, 'stage1')  # calwebb_detector1 pipeline outputs will go here\n",
    "spec2_dir = os.path.join(obs_dir, 'stage2')  # calwebb_spec2 pipeline outputs will go here\n",
    "spec3_dir = os.path.join(obs_dir, 'stage3')  # calwebb_spec3 pipeline outputs will go here\n",
    "\n",
    "# Create desired output directories, if needed\n",
    "os.makedirs(det1_dir, exist_ok=True)\n",
    "os.makedirs(spec2_dir, exist_ok=True)\n",
    "os.makedirs(spec3_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d5e55",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa17b3d",
   "metadata": {},
   "source": [
    "5.<font color='white'>-</font>Detector1 Pipeline<a class=\"anchor\" id=\"det1\"></a>\n",
    "------------------\n",
    "In this section, the uncalibrated data are processed through the Detector1\n",
    "pipeline to create Stage 1 data products, which include 2D countrate\n",
    "images that have been averaged over all integrations (`*_rate.fits` files) and 3D cubes containing fitted ramp slopes for each integration (`*_rateints.fits` files).  The Stage 1 data products have units of DN/s.<br>\n",
    "    \n",
    "By default, all steps in the Detector1 stage of the pipeline are run for\n",
    "MIRI LRS slit mode data sets except the `group_scale`, `ipc`, `refpix`, `clean_flicker_noise`, and `gain_scale` steps.<br>\n",
    "\n",
    "See https://jwst-docs.stsci.edu/jwst-science-calibration-pipeline/stages-of-jwst-data-processing/calwebb_detector1 for a detailed overview of the various pipeline steps that comprise Detector1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de686c5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "To override certain steps and reference files, use the examples provided below.<br>\n",
    "E.g., turn on detection of cosmic ray showers.\n",
    "</div>\n",
    "\n",
    "Set up a dictionary to define how the Detector1 pipeline should be configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2089769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_det1 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13793430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate dictionary setup\n",
    "det1dict = {}\n",
    "det1dict['group_scale'], det1dict['dq_init'], det1dict['emicorr'], det1dict['saturation'], det1dict['ipc'] = {}, {}, {}, {}, {}\n",
    "det1dict['firstframe'], det1dict['lastframe'], det1dict['reset'], det1dict['linearity'], det1dict['rscd'] = {}, {}, {}, {}, {}\n",
    "det1dict['dark_current'], det1dict['refpix'], det1dict['charge_migration'], det1dict['jump'], det1dict['ramp_fit'] = {}, {}, {}, {}, {}\n",
    "det1dict['gain_scale'] = {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#det1dict['emicorr']['skip'] = True\n",
    "\n",
    "# Overrides for various reference files.\n",
    "# If the files are not in the base local directory, provide full path.\n",
    "#det1dict['dq_init']['override_mask'] = 'myfile.fits' # Bad pixel mask\n",
    "#det1dict['saturation']['override_saturation'] = 'myfile.fits' # Saturation\n",
    "#det1dict['reset']['override_reset'] = 'myfile.fits' # Reset\n",
    "#det1dict['linearity']['override_linearity'] = 'myfile.fits' # Linearity\n",
    "#det1dict['rscd']['override_rscd'] = 'myfile.fits' # RSCD\n",
    "#det1dict['dark_current']['override_dark'] = 'myfile.fits' # Dark current subtraction\n",
    "#det1dict['jump']['override_gain'] = 'myfile.fits' # Gain used by jump step\n",
    "#det1dict['ramp_fit']['override_gain'] = 'myfile.fits' # Gain used by ramp fitting step\n",
    "#det1dict['jump']['override_readnoise'] = 'myfile.fits' # Read noise used by jump step\n",
    "#det1dict['ramp_fit']['override_readnoise'] = 'myfile.fits' # Read noise used by ramp fitting step\n",
    "\n",
    "# Turn on multi-core processing for jump step (off by default).  Choose what fraction of cores to use (quarter, half, or all)\n",
    "#det1dict['jump']['maximum_cores'] = 'half'\n",
    "\n",
    "# Turn on detection of cosmic ray showers if desired (off by default)\n",
    "det1dict['jump']['find_showers'] = True\n",
    "\n",
    "# Adjust the flagging threshold for cosmic rays (default is 3.0)\n",
    "det1dict['jump']['rejection_threshold'] = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d984210",
   "metadata": {},
   "source": [
    "Select for only the science data from the observation, excluding target acquisition and/or pointing verification exposures. For the demo example, there should be two files that are selected &mdash; one for each nod position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ac27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all downloaded uncal files\n",
    "uncal_files = sorted(glob.glob(os.path.join(uncal_dir, '*_uncal.fits')))\n",
    "\n",
    "# Only choose science exposures, which have the exposure type setting 'MIR_LRS-FIXEDSLIT'\n",
    "input_files = np.array([fi for fi in uncal_files if fits.getheader(fi, 'PRIMARY')['EXP_TYPE'] == 'MIR_LRS-FIXEDSLIT'])\n",
    "\n",
    "print('Found ' + str(len(input_files)) + ' input uncal files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55221ee8",
   "metadata": {},
   "source": [
    "Run the Detector1 pipeline on the selected uncalibrated data using the call method. This process may take several minutes per file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e818d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline on the selected input files one by one with the custom parameter dictionary \n",
    "if do_det1:\n",
    "    for file in input_files:\n",
    "        Detector1Pipeline.call(file, steps=det1dict, save_results=True, output_dir=det1_dir)\n",
    "else:\n",
    "    print('Skipping Detector1 processing...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\n",
    "print(f\"Runtime for Detector1: {time1 - time_det1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ed82d",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07beff08",
   "metadata": {},
   "source": [
    "6.<font color='white'>-</font>Spec2 Pipeline<a class=\"anchor\" id=\"spec2\"></a>\n",
    "------------------\n",
    "\n",
    "This stage of the pipeline passes the countrate (ramp slope) image products (`*_rate.fits` files) previously generated from\n",
    "Detector1 through the Spec2 (calwebb_spec2) pipeline to yield Stage 2\n",
    "data products (i.e., flux-calibrated flat-fielded detector images `*_cal.fits`, 2D rectified and truncated slit spectrum images `*_s2d.fits`, and quick-look 1D extracted spectra `*_x1d.fits`) for each exposure.  These data products have units of MJy/sr.\n",
    "\n",
    "If <code>bkg_sub = True</code>, an association file will be created that pairs each nod exposure with the other, and the `bkg_subtract` step will be activated to carry out pixel-by-pixel background subtraction. Otherwise, the countrate images will be passed directly through the Spec2 pipeline.\n",
    "\n",
    "See https://jwst-docs.stsci.edu/jwst-science-calibration-pipeline/stages-of-jwst-data-processing/calwebb_spec2 for a detailed overview of the various pipeline steps that comprise Spec2.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "To override certain steps and reference files, use the examples below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13504af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_spec2 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Spec2 pipeline should be configured\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "spec2dict = {}\n",
    "spec2dict['assign_wcs'], spec2dict['badpix_selfcal'], spec2dict['bkg_subtract'], spec2dict['flat_field'], spec2dict['srctype'] = {}, {}, {}, {}, {}\n",
    "spec2dict['straylight'], spec2dict['fringe'], spec2dict['photom'], spec2dict['residual_fringe'], spec2dict['pixel_replace'] = {}, {}, {}, {}, {}\n",
    "spec2dict['cube_build'], spec2dict['extract_1d'] = {}, {}\n",
    "\n",
    "# Activate nod subtraction for background removal, if requested\n",
    "if (bkg_sub is True):\n",
    "    spec2dict['bkg_subtract']['skip'] = False\n",
    "else:\n",
    "    spec2dict['bkg_subtract']['skip'] = True\n",
    "    \n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#spec2dict['straylight']['skip'] = True\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#spec2dict['assign_wcs']['override_distortion'] = 'myfile.asdf' # Spatial distortion (ASDF file)\n",
    "#spec2dict['assign_wcs']['override_specwcs'] = 'myfile.asdf' # Spectral distortion (ASDF file)\n",
    "#spec2dict['flat_field']['override_flat'] = 'myfile.fits' # Pixel flatfield\n",
    "#spec2dict['photom']['override_photom'] = 'myfile.fits' # Photometric calibration array\n",
    "#spec2dict['extract_1d']['override_extract1d'] = 'myfile.asdf' # Spectral extraction parameters (ASDF file)\n",
    "#spec2dict['extract_1d']['override_apcorr'] = 'myfile.asdf' # Aperture correction parameters (ASDF file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65ee2c",
   "metadata": {},
   "source": [
    "Define a function that creates an association file to enable pixel-based background subtraction within Spec2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8268b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writel2asn(scifile, bkgfile, asnfile):\n",
    "    # Define the basic association of the science exposure\n",
    "    asn = afl.asn_from_list([scifile], rule=DMSLevel2bBase)  # Wrap in array since input is single exposure\n",
    "\n",
    "    # Add the background exposure\n",
    "    asn['products'][0]['members'].append({'expname': bkgfile, 'exptype': 'background'})              \n",
    "\n",
    "    # Write the association to a json file\n",
    "    _, serialized = asn.dump()\n",
    "    with open(asnfile, 'w') as outfile:\n",
    "        outfile.write(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ca48d",
   "metadata": {},
   "source": [
    "Construct lists of rate files and corresponding background exposures, ensuring the use of absolute paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rate files from the Detector1 output folder\n",
    "rate_files = sorted(glob.glob(os.path.join(det1_dir, '*rate.fits')))\n",
    "\n",
    "# Use the absolute file paths\n",
    "for ii in range(len(rate_files)):\n",
    "    rate_files[ii] = os.path.abspath(rate_files[ii])\n",
    "rate_files = np.array(rate_files)\n",
    "\n",
    "# Background files are the opposite nod position exposures\n",
    "bkg_files = rate_files[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48631a0",
   "metadata": {},
   "source": [
    "Run the Stage 1 rate files through the Spec2 pipeline. Create ASN files if <code>bkg_sub = True</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline on the selected rate files one by one with the custom parameter dictionary\n",
    "if do_spec2:\n",
    "    for ii, file in enumerate(rate_files):\n",
    "        if bkg_sub:\n",
    "            asnfile = os.path.join(det1_dir, Path(file).stem + '_asn.json')\n",
    "            writel2asn(file, bkg_files[ii], asnfile)\n",
    "            Spec2Pipeline.call(asnfile, steps=spec2dict, save_results=True, output_dir=spec2_dir)\n",
    "        else:\n",
    "            Spec2Pipeline.call(file, steps=spec2dict, save_results=True, output_dir=spec2_dir)\n",
    "            \n",
    "else:\n",
    "    print('Skipping Spec2 processing...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\n",
    "print(f\"Runtime for Spec2: {time1 - time_spec2} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd3d44",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed86a1",
   "metadata": {},
   "source": [
    "7.<font color='white'>-</font>Spec3 Pipeline<a class=\"anchor\" id=\"spec3\"></a>\n",
    "------------------\n",
    "The Spec3 (calwebb_spec3) pipeline produces a Stage 3\n",
    "composite slit spectrum image from both nod exposures and corresponding 1D extracted spectrum.\n",
    "An association file containing both Stage 2 calibrated detector images (`*cal.fits` files) is required for this stage.<br>\n",
    "\n",
    "Note that pixel values in the composite image created by the JWST pipeline are in *surface brightness units* (MJy/sr), not flux units. If the user desires custom spectral extraction outside the context of the `extract1d` step contained within the Spec3 pipeline, the pixel values must be multiplied by the width of the extraction aperture in pixels and the pixel area in steradians in order to obtain a spectrum in the appropriate flux units. This correction is built into the pipeline's `extract1d` algorithm.\n",
    "The nominal pixel area in steradians is provided in the <code>PIXAR_SR</code> keyword and can be found in the SCI extension header of the image outputs.<br>\n",
    "\n",
    "The default pipeline extraction uses a fixed box of width 8 pixels. No in-scene background subtraction is carried out by default. Users can alter the location and width of the extraction aperture and activate background subtraction strategies by providing a custom `extract1d` reference file. For details concerning the proper format and available parameter settings for such reference files, consult https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/reference_files.html#extract1d-reference-file.<br>\n",
    "\n",
    "See https://jwst-docs.stsci.edu/jwst-science-calibration-pipeline/stages-of-jwst-data-processing/calwebb_spec3 for a detailed overview of the various pipeline steps that comprise Spec3.\n",
    "    \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "To override certain steps and reference files, use the examples below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ccadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_spec3 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9bde04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary to define how the Spec3 pipeline should be configured\n",
    "\n",
    "# Boilerplate dictionary setup\n",
    "spec3dict = {}\n",
    "spec3dict['assign_mtwcs'], spec3dict['master_background'], spec3dict['outlier_detection'] = {}, {}, {}\n",
    "spec3dict['pixel_replace'], spec3dict['extract_1d'], spec3dict['spectral_leak'] = {}, {}, {}\n",
    "\n",
    "# Overrides for whether or not certain steps should be skipped (example)\n",
    "#spec3dict['outlier_detection']['skip'] = True\n",
    "\n",
    "# Overrides for various reference files\n",
    "# Files should be in the base local directory or provide full path\n",
    "#spec3dict['extract_1d']['override_extract1d'] = 'myfile.json'  # Spectral extraction parameters (ASDF file)\n",
    "#spec3dict['extract_1d']['override_apcorr'] = 'myfile.asdf'  # Aperture correction parameters (ASDF file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e952ee",
   "metadata": {},
   "source": [
    "The `pixel_replace` step is not run by default, but is recommended for mitigating the effect of bad pixels and other detector artifacts. The default method within the pipeline is to fit a local profile to adjacent pixels and interpolate the flux within the problem region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pixel replacement code to interpolate values for otherwise bad pixels.\n",
    "spec3dict['pixel_replace']['skip'] = False\n",
    "#spec3dict['pixel_replace']['save_results'] = True   # Enable to write out these files for spot checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57079f70",
   "metadata": {},
   "source": [
    "Define a function to create association files for Stage 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writel3asn(cal_files, asnfile):\n",
    "    # Define the basic association of science files\n",
    "    asn = afl.asn_from_list(cal_files, rule=DMS_Level3_Base, product_name='Stage3')\n",
    "\n",
    "    # Write the association to a json file\n",
    "    _, serialized = asn.dump()\n",
    "    with open(asnfile, 'w') as outfile:\n",
    "        outfile.write(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a4735",
   "metadata": {},
   "source": [
    "Find and sort all of the Stage 2 cal files, ensuring the use of absolute paths, and create the association file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cal files from the Spec2 output folder\n",
    "cal_files = sorted(glob.glob(os.path.join(spec2_dir, '*cal.fits')))\n",
    "\n",
    "# Use the absolute file paths\n",
    "for ii in range(len(cal_files)):\n",
    "    cal_files[ii] = os.path.abspath(cal_files[ii])\n",
    "cal_files = np.array(cal_files)\n",
    "\n",
    "# Create association file\n",
    "asnfile = os.path.join(spec3_dir, 'stage3_asn.json')\n",
    "writel3asn(cal_files, asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9f6e0",
   "metadata": {},
   "source": [
    "Run Spec3 using the call method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_spec3:\n",
    "    Spec3Pipeline.call(asnfile, steps=spec3dict, save_results=True, output_dir=spec3_dir)\n",
    "else:\n",
    "    print('Skipping Spec3 processing...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67648f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the time benchmark\n",
    "time1 = time.perf_counter()\n",
    "print(f\"Runtime so far: {time1 - time0:0.4f} seconds\")\n",
    "print(f\"Runtime for Spec3: {time1 - time_spec3} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af962595",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e69ad",
   "metadata": {},
   "source": [
    "8.<font color='white'>-</font>Plot the spectrum<a class=\"anchor\" id=\"plots\"></a>\n",
    "------------------\n",
    "Plot the extracted spectrum to see what the source looks like. The fluxes in the `*x1d.fits` file are in units of Jy.<br>\n",
    "\n",
    "As of September 2024, the absolute flux calibration has been reported to be accurate to within a few percent between 5 and 12 microns. Future improvements are planned to expand the wavelength range for which reliable fluxes can be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_viz:\n",
    "    # Get Stage 3 extracted spectrum\n",
    "    x1d_file = os.path.join(spec3_dir, 'Stage3_x1d.fits')\n",
    "    hdu = fits.open(x1d_file)\n",
    "    objname = hdu[0].header['TARGPROP']\n",
    "    wave = hdu[1].data['WAVELENGTH']\n",
    "    flux = hdu[1].data['FLUX']\n",
    "    hdu.close()\n",
    "    \n",
    "    # Make normal plots\n",
    "    %matplotlib inline\n",
    "    # Interactive plots\n",
    "    #%matplotlib notebook\n",
    "    \n",
    "    # Plot spectrum\n",
    "    rc('axes', linewidth=2)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5), dpi=150)\n",
    "    ax.plot(wave, flux, 'b-', lw=2)\n",
    "    plt.xlabel('Wavelength (Î¼m)')\n",
    "    plt.ylabel('Flux (Jy)')\n",
    "    plt.title(objname, fontsize=14)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(spec3_dir, 'lrs_slit_example_plot.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4c4d6",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b17302",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"https://github.com/spacetelescope/jwst-pipeline-notebooks/raw/main/_static/stsci_footer.png\" alt=\"stsci_logo\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
